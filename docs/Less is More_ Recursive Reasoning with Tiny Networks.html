<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Less is More: Recursive Reasoning with Tiny Networks</title>
<!--Generated on Mon Oct  6 14:56:44 2025 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="/static/browse/0.3.4/css/arxiv-html-papers-20250916.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="reasoning,  recurrent,  arc-agi" lang="en" name="keywords"/>
<base href="/html/2510.04871v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S1" title="In Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S2" title="In Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Background</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S2.SS1" title="In 2 Background ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Structure and goal</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S2.SS2" title="In 2 Background ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Recursion at two different frequencies</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S2.SS3" title="In 2 Background ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Fixed-point recursion with 1-step gradient approximation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S2.SS4" title="In 2 Background ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4 </span>Deep supervision</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S2.SS5" title="In 2 Background ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.5 </span>Adaptive computational time (ACT)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S2.SS6" title="In 2 Background ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.6 </span>Deep supervision and 1-step gradient approximations replaces BPTT</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S2.SS7" title="In 2 Background ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.7 </span>Summary of HRM</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S3" title="In Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Target for improvements in Hierarchical Reasoning Models</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S3.SS1" title="In 3 Target for improvements in Hierarchical Reasoning Models ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Implicit Function Theorem (IFT) with 1-step gradient approximation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S3.SS2" title="In 3 Target for improvements in Hierarchical Reasoning Models ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Twice the forward passes with Adaptive computational time (ACT)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S3.SS3" title="In 3 Target for improvements in Hierarchical Reasoning Models ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Hierarchical interpretation based on complex biological arguments</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S4" title="In Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Tiny Recursion Models</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S4.SS1" title="In 4 Tiny Recursion Models ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>No fixed-point theorem required</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S4.SS2" title="In 4 Tiny Recursion Models ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Simpler reinterpretation of <math alttext="z_{H}" class="ltx_Math" display="inline" intent=":literal"><semantics><msub><mi>z</mi><mi>H</mi></msub><annotation encoding="application/x-tex">z_{H}</annotation></semantics></math> and <math alttext="z_{L}" class="ltx_Math" display="inline" intent=":literal"><semantics><msub><mi>z</mi><mi>L</mi></msub><annotation encoding="application/x-tex">z_{L}</annotation></semantics></math></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S4.SS3" title="In 4 Tiny Recursion Models ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Single network</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S4.SS4" title="In 4 Tiny Recursion Models ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Less is more</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S4.SS5" title="In 4 Tiny Recursion Models ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.5 </span>attention-free architecture for tasks with small fixed context length</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S4.SS6" title="In 4 Tiny Recursion Models ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.6 </span>No additional forward pass needed with ACT</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S4.SS7" title="In 4 Tiny Recursion Models ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.7 </span>Exponential Moving Average (EMA)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S4.SS8" title="In 4 Tiny Recursion Models ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.8 </span>Optimal the number of recursions</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S5" title="In Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S6" title="In Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Less is More: Recursive Reasoning with Tiny Networks</h1>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p">Hierarchical Reasoning Model (HRM) is a novel approach using two small neural networks recursing at different frequencies. This biologically inspired method beats Large Language models (LLMs) on hard puzzle tasks such as Sudoku, Maze, and ARC-AGI while trained with small models (27M parameters) on small data (<math alttext="\sim" class="ltx_Math" display="inline" id="m1" intent=":literal"><semantics><mo>∼</mo><annotation encoding="application/x-tex">\sim</annotation></semantics></math> 1000 examples). HRM holds great promise for solving hard problems with small networks, but it is not yet well understood and may be suboptimal. We propose Tiny Recursive Model (TRM), a much simpler recursive reasoning approach that achieves significantly higher generalization than HRM, while using a single tiny network with only 2 layers. With only 7M parameters, TRM obtains 45% test-accuracy on ARC-AGI-1 and 8% on ARC-AGI-2, higher than most LLMs (e.g., Deepseek R1, o3-mini, Gemini 2.5 Pro) with less than 0.01% of the parameters.</p>
</div>
<div class="ltx_keywords">reasoning, recurrent, arc-agi
</div>
<div class="ltx_logical-block">
<div class="ltx_para" id="p1">
<p class="ltx_p ltx_align_center"><span class="ltx_text ltx_font_bold">Alexia Jolicoeur-Martineau</span></p>
<p class="ltx_p ltx_align_center">Samsung SAIL Montréal</p>
<p class="ltx_p ltx_align_center">alexia.j@samsung.com</p>
</div>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p">While powerful, Large Language models (LLMs) can struggle on hard question-answer problems. Given that they generate their answer auto-regressively, there is a high risk of error since a single incorrect token can render an answer invalid. To improve their reliability, LLMs rely on Chain-of-thoughts (CoT) <cite class="ltx_cite ltx_citemacro_citep">(Wei et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib35" title="">2022</a>)</cite> and Test-Time Compute (TTC) <cite class="ltx_cite ltx_citemacro_citep">(Snell et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib29" title="">2024</a>)</cite>. CoTs seek to emulate human reasoning by having the LLM to sample step-by-step reasoning traces prior to giving their answer. Doing so can improve accuracy, but CoT is expensive, requires high-quality reasoning data (which may not be available), and can be brittle since the generated reasoning may be wrong. To further improve reliability, test-time compute can be used by reporting the most common answer out of <math alttext="K" class="ltx_Math" display="inline" id="S1.p1.m1" intent=":literal"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math> or the highest-reward answer <cite class="ltx_cite ltx_citemacro_citep">(Snell et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib29" title="">2024</a>)</cite>.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="887" id="S1.F1.g1" src="TRM-Page-3.drawio.png" width="449"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Tiny Recursion Model (TRM) recursively improves its predicted answer <math alttext="y" class="ltx_Math" display="inline" id="S1.F1.m15" intent=":literal"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math> with a tiny network. It starts with the embedded input question <math alttext="x" class="ltx_Math" display="inline" id="S1.F1.m16" intent=":literal"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math> and initial embedded answer <math alttext="y" class="ltx_Math" display="inline" id="S1.F1.m17" intent=":literal"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>, and latent <math alttext="z" class="ltx_Math" display="inline" id="S1.F1.m18" intent=":literal"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math>. For up to <math alttext="N_{sup}=16" class="ltx_Math" display="inline" id="S1.F1.m19" intent=":literal"><semantics><mrow><msub><mi>N</mi><mrow><mi>s</mi><mo lspace="0em" rspace="0em">​</mo><mi>u</mi><mo lspace="0em" rspace="0em">​</mo><mi>p</mi></mrow></msub><mo>=</mo><mn>16</mn></mrow><annotation encoding="application/x-tex">N_{sup}=16</annotation></semantics></math> improvements steps, it tries to improve its answer <math alttext="y" class="ltx_Math" display="inline" id="S1.F1.m20" intent=":literal"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>. It does so by i) recursively updating <math alttext="n" class="ltx_Math" display="inline" id="S1.F1.m21" intent=":literal"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math> times its latent <math alttext="z" class="ltx_Math" display="inline" id="S1.F1.m22" intent=":literal"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math> given the question <math alttext="x" class="ltx_Math" display="inline" id="S1.F1.m23" intent=":literal"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math>, current answer <math alttext="y" class="ltx_Math" display="inline" id="S1.F1.m24" intent=":literal"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>, and current latent <math alttext="z" class="ltx_Math" display="inline" id="S1.F1.m25" intent=":literal"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math> (recursive reasoning), and then ii) updating its answer <math alttext="y" class="ltx_Math" display="inline" id="S1.F1.m26" intent=":literal"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math> given the current answer <math alttext="y" class="ltx_Math" display="inline" id="S1.F1.m27" intent=":literal"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math> and current latent <math alttext="z" class="ltx_Math" display="inline" id="S1.F1.m28" intent=":literal"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math>. This recursive process allows the model to progressively improve its answer (potentially addressing any errors from its previous answer) in an extremely parameter-efficient manner while minimizing overfitting.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p">However, this may not be enough. LLMs with CoT and TTC are not enough to beat every problem. While LLMs have made significant progress on ARC-AGI <cite class="ltx_cite ltx_citemacro_citep">(Chollet, <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib6" title="">2019</a>)</cite> since 2019, human-level accuracy still has not been reached (6 years later, as of writing of this paper). Furthermore, LLMs struggle on the newer ARC-AGI-2 (e.g., Gemini 2.5 Pro only obtains 4.9% test accuracy with a high amount of TTC) <cite class="ltx_cite ltx_citemacro_citep">(Chollet et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib7" title="">2025</a>; ARC Prize Foundation, <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib2" title="">2025b</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p">An alternative direction has recently been proposed by <cite class="ltx_cite ltx_citemacro_citet">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib34" title="">2025</a>)</cite>. They propose a new way forward through their novel Hierarchical Reasoning Model (HRM), which obtains high accuracy on puzzle tasks where LLMs struggle to make a dent (e.g., Sudoku solving, Maze pathfinding, and ARC-AGI). HRM is a supervised learning model with two main novelties: 1) <em class="ltx_emph ltx_font_italic">recursive hierarchical reasoning</em>, and 2) <em class="ltx_emph ltx_font_italic">deep supervision</em>.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Recursive hierarchical reasoning</span> consists of recursing multiple times through two small networks (<math alttext="f_{L}" class="ltx_Math" display="inline" id="S1.p4.m1" intent=":literal"><semantics><msub><mi>f</mi><mi>L</mi></msub><annotation encoding="application/x-tex">f_{L}</annotation></semantics></math> at high frequency and <math alttext="f_{H}" class="ltx_Math" display="inline" id="S1.p4.m2" intent=":literal"><semantics><msub><mi>f</mi><mi>H</mi></msub><annotation encoding="application/x-tex">f_{H}</annotation></semantics></math> at low frequency) to predict the answer. Each network generates a different latent feature: <math alttext="f_{L}" class="ltx_Math" display="inline" id="S1.p4.m3" intent=":literal"><semantics><msub><mi>f</mi><mi>L</mi></msub><annotation encoding="application/x-tex">f_{L}</annotation></semantics></math> outputs <math alttext="z_{H}" class="ltx_Math" display="inline" id="S1.p4.m4" intent=":literal"><semantics><msub><mi>z</mi><mi>H</mi></msub><annotation encoding="application/x-tex">z_{H}</annotation></semantics></math> and <math alttext="f_{H}" class="ltx_Math" display="inline" id="S1.p4.m5" intent=":literal"><semantics><msub><mi>f</mi><mi>H</mi></msub><annotation encoding="application/x-tex">f_{H}</annotation></semantics></math> outputs <math alttext="z_{L}" class="ltx_Math" display="inline" id="S1.p4.m6" intent=":literal"><semantics><msub><mi>z</mi><mi>L</mi></msub><annotation encoding="application/x-tex">z_{L}</annotation></semantics></math>. Both features (<math alttext="z_{L},z_{H}" class="ltx_Math" display="inline" id="S1.p4.m7" intent=":literal"><semantics><mrow><msub><mi>z</mi><mi>L</mi></msub><mo>,</mo><msub><mi>z</mi><mi>H</mi></msub></mrow><annotation encoding="application/x-tex">z_{L},z_{H}</annotation></semantics></math>) are used as input to the two networks. The authors provide some biological arguments in favor of recursing at different hierarchies based on the different temporal frequencies at which the brains operate and hierarchical processing of sensory inputs.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Deep supervision</span> consists of improving the answer through multiple supervision steps while carrying the two latent features as initialization for the improvement steps (after detaching them from the computational graph so that their gradients do not propagate). This provide residual connections, which emulates very deep neural networks that are too memory expensive to apply in one forward pass.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p">An independent analysis on the ARC-AGI benchmark showed that deep supervision seems to be the primary driver of the performance gains <cite class="ltx_cite ltx_citemacro_citep">(ARC Prize Foundation, <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib1" title="">2025a</a>)</cite>. Using <em class="ltx_emph ltx_font_italic">deep supervision</em> doubled accuracy over single-step supervision (going from <math alttext="19\%" class="ltx_Math" display="inline" id="S1.p6.m1" intent=":literal"><semantics><mrow><mn>19</mn><mo>%</mo></mrow><annotation encoding="application/x-tex">19\%</annotation></semantics></math> to <math alttext="39\%" class="ltx_Math" display="inline" id="S1.p6.m2" intent=":literal"><semantics><mrow><mn>39</mn><mo>%</mo></mrow><annotation encoding="application/x-tex">39\%</annotation></semantics></math> accuracy), while <em class="ltx_emph ltx_font_italic">recursive hierarchical reasoning</em> only slightly improved accuracy over a regular model with a single forward pass (going from <math alttext="35.7\%" class="ltx_Math" display="inline" id="S1.p6.m3" intent=":literal"><semantics><mrow><mn>35.7</mn><mo>%</mo></mrow><annotation encoding="application/x-tex">35.7\%</annotation></semantics></math> to <math alttext="39.0\%" class="ltx_Math" display="inline" id="S1.p6.m4" intent=":literal"><semantics><mrow><mn>39.0</mn><mo>%</mo></mrow><annotation encoding="application/x-tex">39.0\%</annotation></semantics></math> accuracy). This suggests that reasoning across different supervision steps is worth it, but the recursion done in each supervision step is not particularly important.</p>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p">In this work, we show that the benefit from <em class="ltx_emph ltx_font_italic">recursive reasoning</em> can be massively improved, making it much more than incremental. We propose Tiny Recursive Model (TRM), an improved and simplified approach using a much smaller tiny network with only 2 layers that achieves significantly higher generalization than HRM on a variety of problems. In doing so, we improve the state-of-the-art test accuracy on Sudoku-Extreme from 55% to 87%, Maze-Hard from 75% to 85%, ARC-AGI-1 from 40% to 45%, and ARC-AGI-2 from 5% to 8%.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p">HRM is described in Algorithm <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S2.F2" title="Figure 2 ‣ 2.1 Structure and goal ‣ 2 Background ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_tag">2</span></a>. We discuss the details of the algorithm further below.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Structure and goal</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p">The focus of HRM is supervised learning. Given an input, produce an output. Both input and output are assumed to have shape <math alttext="[B,L]" class="ltx_Math" display="inline" id="S2.SS1.p1.m1" intent=":literal"><semantics><mrow><mo stretchy="false">[</mo><mi>B</mi><mo>,</mo><mi>L</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[B,L]</annotation></semantics></math> (when the shape differs, padding tokens can be added), where <math alttext="B" class="ltx_Math" display="inline" id="S2.SS1.p1.m2" intent=":literal"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math> is the batch-size and <math alttext="L" class="ltx_Math" display="inline" id="S2.SS1.p1.m3" intent=":literal"><semantics><mi>L</mi><annotation encoding="application/x-tex">L</annotation></semantics></math> is the context-length.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p">HRM contains four learnable components: the input embedding <math alttext="f_{I}(\cdot;\theta_{I})" class="ltx_Math" display="inline" id="S2.SS1.p2.m1" intent=":literal"><semantics><mrow><msub><mi>f</mi><mi>I</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mo lspace="0em" rspace="0em">⋅</mo><mo>;</mo><msub><mi>θ</mi><mi>I</mi></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">f_{I}(\cdot;\theta_{I})</annotation></semantics></math>, low-level recurrent network <math alttext="f_{L}(\cdot;\theta_{L})" class="ltx_Math" display="inline" id="S2.SS1.p2.m2" intent=":literal"><semantics><mrow><msub><mi>f</mi><mi>L</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mo lspace="0em" rspace="0em">⋅</mo><mo>;</mo><msub><mi>θ</mi><mi>L</mi></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">f_{L}(\cdot;\theta_{L})</annotation></semantics></math>, high-level recurrent network <math alttext="f_{H}(\cdot;\theta_{H})" class="ltx_Math" display="inline" id="S2.SS1.p2.m3" intent=":literal"><semantics><mrow><msub><mi>f</mi><mi>H</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mo lspace="0em" rspace="0em">⋅</mo><mo>;</mo><msub><mi>θ</mi><mi>H</mi></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">f_{H}(\cdot;\theta_{H})</annotation></semantics></math>, and the output head <math alttext="f_{O}(\cdot;\theta_{O})" class="ltx_Math" display="inline" id="S2.SS1.p2.m4" intent=":literal"><semantics><mrow><msub><mi>f</mi><mi>O</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mo lspace="0em" rspace="0em">⋅</mo><mo>;</mo><msub><mi>θ</mi><mi>O</mi></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">f_{O}(\cdot;\theta_{O})</annotation></semantics></math>. Once the input is embedded, the shape becomes <math alttext="[B,L,D]" class="ltx_Math" display="inline" id="S2.SS1.p2.m5" intent=":literal"><semantics><mrow><mo stretchy="false">[</mo><mi>B</mi><mo>,</mo><mi>L</mi><mo>,</mo><mi>D</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[B,L,D]</annotation></semantics></math> where <math alttext="D" class="ltx_Math" display="inline" id="S2.SS1.p2.m6" intent=":literal"><semantics><mi>D</mi><annotation encoding="application/x-tex">D</annotation></semantics></math> is the embedding size. Each network is a 4-layer Transformers architecture <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib33" title="">2017</a>)</cite>, with RMSNorm <cite class="ltx_cite ltx_citemacro_citep">(Zhang &amp; Sennrich, <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib38" title="">2019</a>)</cite>, no bias <cite class="ltx_cite ltx_citemacro_citep">(Chowdhery et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib8" title="">2023</a>)</cite>, rotary embeddings <cite class="ltx_cite ltx_citemacro_citep">(Su et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib31" title="">2024</a>)</cite>, and SwiGLU activation function <cite class="ltx_cite ltx_citemacro_citep">(Hendrycks &amp; Gimpel, <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib13" title="">2016</a>; Shazeer, <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib27" title="">2020</a>)</cite>.</p>
</div>
<figure class="ltx_figure" id="S2.F2">
<div class="ltx_listing ltx_lst_language_python ltx_lstlisting ltx_align_center ltx_listing" style="--ltx-bg-color:#FFFFFF;">
<div class="ltx_listing_data"><a download="" href="data:text/plain;base64,ZGVmIGhybSh6LCB4LCBuPTIsIFQ9Mik6ICMgaGllcmFyY2hpY2FsIHJlYXNvbmluZwogICAgekgsIHpMID0gegogICAgd2l0aCB0b3JjaC5ub19ncmFkKCk6CiAgICAgICAgZm9yIGkgaW4gcmFuZ2UoblQgLSAyKToKICAgICAgICAgICAgekwgPSBMX25ldCh6TCwgekgsIHgpCiAgICAgICAgICAgIGlmIChpICsgMSkgJSBUID09IDA6CiAgICAgICAgICAgICAgICB6SCA9IEhfbmV0KHpILCB6TCkKICAgICMgMS1zdGVwIGdyYWQKICAgIHpMID0gTF9uZXQoekwsIHpILCB4KQogICAgekggPSBIX25ldCh6SCwgekwpCiAgICByZXR1cm4gKHpILCB6TCksIG91dHB1dF9oZWFkKHpIKSwgUV9oZWFkKHpIKQoKZGVmIEFDVF9oYWx0KHEsIHlfaGF0LCB5X3RydWUpOgogICAgdGFyZ2V0X2hhbHQgPSAoeV9oYXQgPT0geV90cnVlKQogICAgbG9zcyA9IDAuNSpiaW5hcnlfY3Jvc3NfZW50cm9weShxWzBdLCB0YXJnZXRfaGFsdCkKICAgIHJldHVybiBsb3NzCgpkZWYgQUNUX2NvbnRpbnVlKHEsIGxhc3Rfc3RlcCk6CiAgICBpZiBsYXN0X3N0ZXA6CiAgICAgICAgdGFyZ2V0X2NvbnRpbnVlID0gc2lnbW9pZChxWzBdKQogICAgZWxzZToKICAgICAgICB0YXJnZXRfY29udGludWUgPSBzaWdtb2lkKG1heChxWzBdLCBxWzFdKSkpCiAgICBsb3NzID0gMC41KmJpbmFyeV9jcm9zc19lbnRyb3B5KHFbMV0sIHRhcmdldF9jb250aW51ZSkKICAgIHJldHVybiBsb3NzCgojIERlZXAgU3VwZXJ2aXNpb24KZm9yIHhfaW5wdXQsIHlfdHJ1ZSBpbiB0cmFpbl9kYXRhbG9hZGVyOgogICAgeiA9IHpfaW5pdAogICAgZm9yIHN0ZXAgaW4gcmFuZ2UoTl9zdXApOiAjIGRlZXAgc3VwZXJ2aXNpb24KICAgICAgICB4ID0gaW5wdXRfZW1iZWRkaW5nKHhfaW5wdXQpCiAgICAgICAgeiwgeV9wcmVkLCBxID0gaHJtKHosIHgpCiAgICAgICAgbG9zcyA9IHNvZnRtYXhfY3Jvc3NfZW50cm9weSh5X3ByZWQsIHlfdHJ1ZSkKICAgICAgICAjIEFkYXB0aXZlIGNvbXB1dGF0aW9uYWwgdGltZSAoQUNUKSB1c2luZyBRLWxlYXJuaW5nCiAgICAgICAgbG9zcyArPSBBQ1RfaGFsdChxLCB5X3ByZWQsIHlfdHJ1ZSkKICAgICAgICBfLCBfLCBxX25leHQgPSBocm0oeiwgeCkgIyBleHRyYSBmb3J3YXJkIHBhc3MKICAgICAgICBsb3NzICs9IEFDVF9jb250aW51ZShxX25leHQsIHN0ZXAgPT0gTl9zdXAgLSAxKQogICAgICAgIHogPSB6LmRldGFjaCgpCiAgICAgICAgbG9zcy5iYWNrd2FyZCgpCiAgICAgICAgb3B0LnN0ZXAoKQogICAgICAgIG9wdC56ZXJvX2dyYWQoKQogICAgICAgIGlmIHFbMF0gPiBxWzFdOiAjIGVhcmx5LXN0b3BwaW5nCiAgICAgICAgICAgIGJyZWFr">⬇</a></div>
<div class="ltx_listingline" id="lstnumberx1">
<span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">def</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">hrm</span>(<span class="ltx_text ltx_lst_identifier">z</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">x</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">n</span>=2,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">T</span>=2):<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_comment" style="--ltx-fg-color:#808080;">#<span class="ltx_text ltx_lst_space"> </span>hierarchical<span class="ltx_text ltx_lst_space"> </span>reasoning</span>
</div>
<div class="ltx_listingline" id="lstnumberx2">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">zH</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">zL</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>
</div>
<div class="ltx_listingline" id="lstnumberx3">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">with</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">torch</span>.<span class="ltx_text ltx_lst_identifier">no_grad</span>():
</div>
<div class="ltx_listingline" id="lstnumberx4">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">for</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">i</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">in</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword ltx_lst_keywords2" style="--ltx-fg-color:#0000FF;">range</span>(<span class="ltx_text ltx_lst_identifier">nT</span><span class="ltx_text ltx_lst_space"> </span>-<span class="ltx_text ltx_lst_space"> </span>2):
</div>
<div class="ltx_listingline" id="lstnumberx5">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">zL</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">L_net</span>(<span class="ltx_text ltx_lst_identifier">zL</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">zH</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">x</span>)
</div>
<div class="ltx_listingline" id="lstnumberx6">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">if</span><span class="ltx_text ltx_lst_space"> </span>(<span class="ltx_text ltx_lst_identifier">i</span><span class="ltx_text ltx_lst_space"> </span>+<span class="ltx_text ltx_lst_space"> </span>1)<span class="ltx_text ltx_lst_space"> </span>%<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">T</span><span class="ltx_text ltx_lst_space"> </span>==<span class="ltx_text ltx_lst_space"> </span>0:
</div>
<div class="ltx_listingline" id="lstnumberx7">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">zH</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">H_net</span>(<span class="ltx_text ltx_lst_identifier">zH</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">zL</span>)
</div>
<div class="ltx_listingline" id="lstnumberx8">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_comment" style="--ltx-fg-color:#808080;">#<span class="ltx_text ltx_lst_space"> </span>1-step<span class="ltx_text ltx_lst_space"> </span>grad</span>
</div>
<div class="ltx_listingline" id="lstnumberx9">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">zL</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">L_net</span>(<span class="ltx_text ltx_lst_identifier">zL</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">zH</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">x</span>)
</div>
<div class="ltx_listingline" id="lstnumberx10">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">zH</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">H_net</span>(<span class="ltx_text ltx_lst_identifier">zH</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">zL</span>)
</div>
<div class="ltx_listingline" id="lstnumberx11">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">return</span><span class="ltx_text ltx_lst_space"> </span>(<span class="ltx_text ltx_lst_identifier">zH</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">zL</span>),<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">output_head</span>(<span class="ltx_text ltx_lst_identifier">zH</span>),<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">Q_head</span>(<span class="ltx_text ltx_lst_identifier">zH</span>)
</div>
<div class="ltx_listingline" id="lstnumberx12">
</div>
<div class="ltx_listingline" id="lstnumberx13">
<span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">def</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">ACT_halt</span>(<span class="ltx_text ltx_lst_identifier">q</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y_hat</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y_true</span>):
</div>
<div class="ltx_listingline" id="lstnumberx14">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">target_halt</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span>(<span class="ltx_text ltx_lst_identifier">y_hat</span><span class="ltx_text ltx_lst_space"> </span>==<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y_true</span>)
</div>
<div class="ltx_listingline" id="lstnumberx15">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">loss</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span>0.5*<span class="ltx_text ltx_lst_identifier">binary_cross_entropy</span>(<span class="ltx_text ltx_lst_identifier">q</span>[0],<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">target_halt</span>)
</div>
<div class="ltx_listingline" id="lstnumberx16">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">return</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">loss</span>
</div>
<div class="ltx_listingline" id="lstnumberx17">
</div>
<div class="ltx_listingline" id="lstnumberx18">
<span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">def</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">ACT_continue</span>(<span class="ltx_text ltx_lst_identifier">q</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">last_step</span>):
</div>
<div class="ltx_listingline" id="lstnumberx19">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">if</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">last_step</span>:
</div>
<div class="ltx_listingline" id="lstnumberx20">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">target_continue</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">sigmoid</span>(<span class="ltx_text ltx_lst_identifier">q</span>[0])
</div>
<div class="ltx_listingline" id="lstnumberx21">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">else</span>:
</div>
<div class="ltx_listingline" id="lstnumberx22">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">target_continue</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">sigmoid</span>(<span class="ltx_text ltx_lst_keyword ltx_lst_keywords2" style="--ltx-fg-color:#0000FF;">max</span>(<span class="ltx_text ltx_lst_identifier">q</span>[0],<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">q</span>[1])))
</div>
<div class="ltx_listingline" id="lstnumberx23">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">loss</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span>0.5*<span class="ltx_text ltx_lst_identifier">binary_cross_entropy</span>(<span class="ltx_text ltx_lst_identifier">q</span>[1],<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">target_continue</span>)
</div>
<div class="ltx_listingline" id="lstnumberx24">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">return</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">loss</span>
</div>
<div class="ltx_listingline" id="lstnumberx25">
</div>
<div class="ltx_listingline" id="lstnumberx26">
<span class="ltx_text ltx_lst_comment" style="--ltx-fg-color:#808080;">#<span class="ltx_text ltx_lst_space"> </span>Deep<span class="ltx_text ltx_lst_space"> </span>Supervision</span>
</div>
<div class="ltx_listingline" id="lstnumberx27">
<span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">for</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">x_input</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y_true</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">in</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">train_dataloader</span>:
</div>
<div class="ltx_listingline" id="lstnumberx28">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z_init</span>
</div>
<div class="ltx_listingline" id="lstnumberx29">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">for</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">step</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">in</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword ltx_lst_keywords2" style="--ltx-fg-color:#0000FF;">range</span>(<span class="ltx_text ltx_lst_identifier">N_sup</span>):<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_comment" style="--ltx-fg-color:#808080;">#<span class="ltx_text ltx_lst_space"> </span>deep<span class="ltx_text ltx_lst_space"> </span>supervision</span>
</div>
<div class="ltx_listingline" id="lstnumberx30">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">x</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">input_embedding</span>(<span class="ltx_text ltx_lst_identifier">x_input</span>)
</div>
<div class="ltx_listingline" id="lstnumberx31">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y_pred</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">q</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">hrm</span>(<span class="ltx_text ltx_lst_identifier">z</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">x</span>)
</div>
<div class="ltx_listingline" id="lstnumberx32">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">loss</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">softmax_cross_entropy</span>(<span class="ltx_text ltx_lst_identifier">y_pred</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y_true</span>)
</div>
<div class="ltx_listingline" id="lstnumberx33">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_comment" style="--ltx-fg-color:#808080;">#<span class="ltx_text ltx_lst_space"> </span>Adaptive<span class="ltx_text ltx_lst_space"> </span>computational<span class="ltx_text ltx_lst_space"> </span>time<span class="ltx_text ltx_lst_space"> </span>(ACT)<span class="ltx_text ltx_lst_space"> </span>using<span class="ltx_text ltx_lst_space"> </span>Q-learning</span>
</div>
<div class="ltx_listingline" id="lstnumberx34">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">loss</span><span class="ltx_text ltx_lst_space"> </span>+=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">ACT_halt</span>(<span class="ltx_text ltx_lst_identifier">q</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y_pred</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y_true</span>)
</div>
<div class="ltx_listingline" id="lstnumberx35">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">_</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">_</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">q_next</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">hrm</span>(<span class="ltx_text ltx_lst_identifier">z</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">x</span>)<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_comment" style="--ltx-fg-color:#808080;">#<span class="ltx_text ltx_lst_space"> </span>extra<span class="ltx_text ltx_lst_space"> </span>forward<span class="ltx_text ltx_lst_space"> </span>pass</span>
</div>
<div class="ltx_listingline" id="lstnumberx36">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">loss</span><span class="ltx_text ltx_lst_space"> </span>+=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">ACT_continue</span>(<span class="ltx_text ltx_lst_identifier">q_next</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">step</span><span class="ltx_text ltx_lst_space"> </span>==<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">N_sup</span><span class="ltx_text ltx_lst_space"> </span>-<span class="ltx_text ltx_lst_space"> </span>1)
</div>
<div class="ltx_listingline" id="lstnumberx37">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>.<span class="ltx_text ltx_lst_identifier">detach</span>()
</div>
<div class="ltx_listingline" id="lstnumberx38">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">loss</span>.<span class="ltx_text ltx_lst_identifier">backward</span>()
</div>
<div class="ltx_listingline" id="lstnumberx39">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">opt</span>.<span class="ltx_text ltx_lst_identifier">step</span>()
</div>
<div class="ltx_listingline" id="lstnumberx40">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">opt</span>.<span class="ltx_text ltx_lst_identifier">zero_grad</span>()
</div>
<div class="ltx_listingline" id="lstnumberx41">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">if</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">q</span>[0]<span class="ltx_text ltx_lst_space"> </span>&gt;<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">q</span>[1]:<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_comment" style="--ltx-fg-color:#808080;">#<span class="ltx_text ltx_lst_space"> </span>early-stopping</span>
</div>
<div class="ltx_listingline" id="lstnumberx42">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">break</span>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Pseudocode of Hierarchical Reasoning Models (HRMs).</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Recursion at two different frequencies</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p">Given the hyperparameters used by <cite class="ltx_cite ltx_citemacro_citet">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib34" title="">2025</a>)</cite> (<math alttext="n=2" class="ltx_Math" display="inline" id="S2.SS2.p1.m1" intent=":literal"><semantics><mrow><mi>n</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">n=2</annotation></semantics></math> <math alttext="f_{L}" class="ltx_Math" display="inline" id="S2.SS2.p1.m2" intent=":literal"><semantics><msub><mi>f</mi><mi>L</mi></msub><annotation encoding="application/x-tex">f_{L}</annotation></semantics></math> steps, 1 <math alttext="f_{H}" class="ltx_Math" display="inline" id="S2.SS2.p1.m3" intent=":literal"><semantics><msub><mi>f</mi><mi>H</mi></msub><annotation encoding="application/x-tex">f_{H}</annotation></semantics></math> steps; done <math alttext="T=2" class="ltx_Math" display="inline" id="S2.SS2.p1.m4" intent=":literal"><semantics><mrow><mi>T</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">T=2</annotation></semantics></math> times), a forward pass of HRM is done as follows:</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="Ax4.EGx1">
<tbody id="S2.Ex1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle x" class="ltx_Math" display="inline" id="S2.Ex1.m1" intent=":literal"><semantics><mi>x</mi><annotation encoding="application/x-tex">\displaystyle x</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\leftarrow f_{I}(\tilde{x})" class="ltx_Math" display="inline" id="S2.Ex1.m2" intent=":literal"><semantics><mrow><mi></mi><mo stretchy="false">←</mo><mrow><msub><mi>f</mi><mi>I</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mover accent="true"><mi>x</mi><mo>~</mo></mover><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\leftarrow f_{I}(\tilde{x})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.Ex2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle z_{L}" class="ltx_Math" display="inline" id="S2.Ex2.m1" intent=":literal"><semantics><msub><mi>z</mi><mi>L</mi></msub><annotation encoding="application/x-tex">\displaystyle z_{L}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\leftarrow f_{L}\left(z_{L}+z_{H}+x\right)\hskip 6.0pt\text{\# without gradients}" class="ltx_Math" display="inline" id="S2.Ex2.m2" intent=":literal"><semantics><mrow><mi></mi><mo stretchy="false">←</mo><mrow><msub><mi>f</mi><mi>L</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo>(</mo><mrow><msub><mi>z</mi><mi>L</mi></msub><mo>+</mo><msub><mi>z</mi><mi>H</mi></msub><mo>+</mo><mi>x</mi></mrow><mo>)</mo></mrow><mo lspace="0.600em" rspace="0em">​</mo><mtext># without gradients</mtext></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\leftarrow f_{L}\left(z_{L}+z_{H}+x\right)\hskip 6.0pt\text{\# without gradients}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.Ex3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle z_{L}" class="ltx_Math" display="inline" id="S2.Ex3.m1" intent=":literal"><semantics><msub><mi>z</mi><mi>L</mi></msub><annotation encoding="application/x-tex">\displaystyle z_{L}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\leftarrow f_{L}\left(z_{L}+z_{H}+x\right)\hskip 6.0pt\text{\# without gradients}" class="ltx_Math" display="inline" id="S2.Ex3.m2" intent=":literal"><semantics><mrow><mi></mi><mo stretchy="false">←</mo><mrow><msub><mi>f</mi><mi>L</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo>(</mo><mrow><msub><mi>z</mi><mi>L</mi></msub><mo>+</mo><msub><mi>z</mi><mi>H</mi></msub><mo>+</mo><mi>x</mi></mrow><mo>)</mo></mrow><mo lspace="0.600em" rspace="0em">​</mo><mtext># without gradients</mtext></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\leftarrow f_{L}\left(z_{L}+z_{H}+x\right)\hskip 6.0pt\text{\# without gradients}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.Ex4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle z_{H}" class="ltx_Math" display="inline" id="S2.Ex4.m1" intent=":literal"><semantics><msub><mi>z</mi><mi>H</mi></msub><annotation encoding="application/x-tex">\displaystyle z_{H}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\leftarrow f_{H}\left(z_{L}+z_{H}\right)\hskip 22.0pt\text{\# without gradients}" class="ltx_Math" display="inline" id="S2.Ex4.m2" intent=":literal"><semantics><mrow><mi></mi><mo stretchy="false">←</mo><mrow><mrow><msub><mi>f</mi><mi>H</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo>(</mo><mrow><msub><mi>z</mi><mi>L</mi></msub><mo>+</mo><msub><mi>z</mi><mi>H</mi></msub></mrow><mo>)</mo></mrow></mrow><mspace style="width:2.2em;" width="2.2em"></mspace><mtext># without gradients</mtext></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\leftarrow f_{H}\left(z_{L}+z_{H}\right)\hskip 22.0pt\text{\# without gradients}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.Ex5"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle z_{L}" class="ltx_Math" display="inline" id="S2.Ex5.m1" intent=":literal"><semantics><msub><mi>z</mi><mi>L</mi></msub><annotation encoding="application/x-tex">\displaystyle z_{L}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\leftarrow f_{L}\left(z_{L}+z_{H}+x\right)\hskip 6.0pt\text{\# without gradients}" class="ltx_Math" display="inline" id="S2.Ex5.m2" intent=":literal"><semantics><mrow><mi></mi><mo stretchy="false">←</mo><mrow><msub><mi>f</mi><mi>L</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo>(</mo><mrow><msub><mi>z</mi><mi>L</mi></msub><mo>+</mo><msub><mi>z</mi><mi>H</mi></msub><mo>+</mo><mi>x</mi></mrow><mo>)</mo></mrow><mo lspace="0.600em" rspace="0em">​</mo><mtext># without gradients</mtext></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\leftarrow f_{L}\left(z_{L}+z_{H}+x\right)\hskip 6.0pt\text{\# without gradients}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.Ex6"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle z_{L}" class="ltx_Math" display="inline" id="S2.Ex6.m1" intent=":literal"><semantics><msub><mi>z</mi><mi>L</mi></msub><annotation encoding="application/x-tex">\displaystyle z_{L}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\leftarrow z_{L}.detach()" class="ltx_Math" display="inline" id="S2.Ex6.m2" intent=":literal"><semantics><mrow><mrow><mi></mi><mo stretchy="false">←</mo><msub><mi>z</mi><mi>L</mi></msub></mrow><mo lspace="0em" rspace="0.167em">.</mo><mrow><mi>d</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>t</mi><mo lspace="0em" rspace="0em">​</mo><mi>a</mi><mo lspace="0em" rspace="0em">​</mo><mi>c</mi><mo lspace="0em" rspace="0em">​</mo><mi>h</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\leftarrow z_{L}.detach()</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.Ex7"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle z_{H}" class="ltx_Math" display="inline" id="S2.Ex7.m1" intent=":literal"><semantics><msub><mi>z</mi><mi>H</mi></msub><annotation encoding="application/x-tex">\displaystyle z_{H}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\leftarrow z_{H}.detach()" class="ltx_Math" display="inline" id="S2.Ex7.m2" intent=":literal"><semantics><mrow><mrow><mi></mi><mo stretchy="false">←</mo><msub><mi>z</mi><mi>H</mi></msub></mrow><mo lspace="0em" rspace="0.167em">.</mo><mrow><mi>d</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>t</mi><mo lspace="0em" rspace="0em">​</mo><mi>a</mi><mo lspace="0em" rspace="0em">​</mo><mi>c</mi><mo lspace="0em" rspace="0em">​</mo><mi>h</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\leftarrow z_{H}.detach()</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.Ex8"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle z_{L}" class="ltx_Math" display="inline" id="S2.Ex8.m1" intent=":literal"><semantics><msub><mi>z</mi><mi>L</mi></msub><annotation encoding="application/x-tex">\displaystyle z_{L}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\leftarrow f_{L}\left(z_{L}+z_{H}+x\right)\hskip 6.0pt\text{\# with gradients}" class="ltx_Math" display="inline" id="S2.Ex8.m2" intent=":literal"><semantics><mrow><mi></mi><mo stretchy="false">←</mo><mrow><msub><mi>f</mi><mi>L</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo>(</mo><mrow><msub><mi>z</mi><mi>L</mi></msub><mo>+</mo><msub><mi>z</mi><mi>H</mi></msub><mo>+</mo><mi>x</mi></mrow><mo>)</mo></mrow><mo lspace="0.600em" rspace="0em">​</mo><mtext># with gradients</mtext></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\leftarrow f_{L}\left(z_{L}+z_{H}+x\right)\hskip 6.0pt\text{\# with gradients}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.Ex9"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle z_{H}" class="ltx_Math" display="inline" id="S2.Ex9.m1" intent=":literal"><semantics><msub><mi>z</mi><mi>H</mi></msub><annotation encoding="application/x-tex">\displaystyle z_{H}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\leftarrow f_{H}\left(z_{L}+z_{H}\right)\hskip 22.0pt\text{\# with gradients}" class="ltx_Math" display="inline" id="S2.Ex9.m2" intent=":literal"><semantics><mrow><mi></mi><mo stretchy="false">←</mo><mrow><mrow><msub><mi>f</mi><mi>H</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo>(</mo><mrow><msub><mi>z</mi><mi>L</mi></msub><mo>+</mo><msub><mi>z</mi><mi>H</mi></msub></mrow><mo>)</mo></mrow></mrow><mspace style="width:2.2em;" width="2.2em"></mspace><mtext># with gradients</mtext></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\leftarrow f_{H}\left(z_{L}+z_{H}\right)\hskip 22.0pt\text{\# with gradients}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.Ex10"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\hat{y}" class="ltx_Math" display="inline" id="S2.Ex10.m1" intent=":literal"><semantics><mover accent="true"><mi>y</mi><mo>^</mo></mover><annotation encoding="application/x-tex">\displaystyle\hat{y}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\leftarrow\text{argmax}(f_{O}\left(z_{H}\right))" class="ltx_Math" display="inline" id="S2.Ex10.m2" intent=":literal"><semantics><mrow><mi></mi><mo stretchy="false">←</mo><mrow><mtext>argmax</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><msub><mi>f</mi><mi>O</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo>(</mo><msub><mi>z</mi><mi>H</mi></msub><mo>)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\leftarrow\text{argmax}(f_{O}\left(z_{H}\right))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p">where <math alttext="\hat{y}" class="ltx_Math" display="inline" id="S2.SS2.p2.m1" intent=":literal"><semantics><mover accent="true"><mi>y</mi><mo>^</mo></mover><annotation encoding="application/x-tex">\hat{y}</annotation></semantics></math> is the predicted output answer, <math alttext="z_{L}" class="ltx_Math" display="inline" id="S2.SS2.p2.m2" intent=":literal"><semantics><msub><mi>z</mi><mi>L</mi></msub><annotation encoding="application/x-tex">z_{L}</annotation></semantics></math> and <math alttext="z_{H}" class="ltx_Math" display="inline" id="S2.SS2.p2.m3" intent=":literal"><semantics><msub><mi>z</mi><mi>H</mi></msub><annotation encoding="application/x-tex">z_{H}</annotation></semantics></math> are either initialized embeddings or the embeddings of the previous deep supervision step (after detaching them from the computational graph). As can be seen, a forward pass of HRM consists of applying 6 function evaluations, where the first 4 function evaluations are detached from the computational graph and are not back-propagated through. The authors uses <math alttext="n=2" class="ltx_Math" display="inline" id="S2.SS2.p2.m4" intent=":literal"><semantics><mrow><mi>n</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">n=2</annotation></semantics></math> with <math alttext="T=2" class="ltx_Math" display="inline" id="S2.SS2.p2.m5" intent=":literal"><semantics><mrow><mi>T</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">T=2</annotation></semantics></math> in all experiments, but HRM can be generalized by allowing for an arbitrary number of L steps (<math alttext="n" class="ltx_Math" display="inline" id="S2.SS2.p2.m6" intent=":literal"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>) and recursions (<math alttext="T" class="ltx_Math" display="inline" id="S2.SS2.p2.m7" intent=":literal"><semantics><mi>T</mi><annotation encoding="application/x-tex">T</annotation></semantics></math>) as shown in Algorithm <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S2.F2" title="Figure 2 ‣ 2.1 Structure and goal ‣ 2 Background ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Fixed-point recursion with 1-step gradient approximation</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p">Assuming that (<math alttext="z_{L}" class="ltx_Math" display="inline" id="S2.SS3.p1.m1" intent=":literal"><semantics><msub><mi>z</mi><mi>L</mi></msub><annotation encoding="application/x-tex">z_{L}</annotation></semantics></math>, <math alttext="z_{H}" class="ltx_Math" display="inline" id="S2.SS3.p1.m2" intent=":literal"><semantics><msub><mi>z</mi><mi>H</mi></msub><annotation encoding="application/x-tex">z_{H}</annotation></semantics></math>) reaches a fixed-point (<math alttext="z_{L}^{*}" class="ltx_Math" display="inline" id="S2.SS3.p1.m3" intent=":literal"><semantics><msubsup><mi>z</mi><mi>L</mi><mo>∗</mo></msubsup><annotation encoding="application/x-tex">z_{L}^{*}</annotation></semantics></math>, <math alttext="z_{H}^{*}" class="ltx_Math" display="inline" id="S2.SS3.p1.m4" intent=":literal"><semantics><msubsup><mi>z</mi><mi>H</mi><mo>∗</mo></msubsup><annotation encoding="application/x-tex">z_{H}^{*}</annotation></semantics></math>) through recursing from both <math alttext="f_{L}" class="ltx_Math" display="inline" id="S2.SS3.p1.m5" intent=":literal"><semantics><msub><mi>f</mi><mi>L</mi></msub><annotation encoding="application/x-tex">f_{L}</annotation></semantics></math> and <math alttext="f_{H}" class="ltx_Math" display="inline" id="S2.SS3.p1.m6" intent=":literal"><semantics><msub><mi>f</mi><mi>H</mi></msub><annotation encoding="application/x-tex">f_{H}</annotation></semantics></math>,</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="Ax4.EGx2">
<tbody id="S2.Ex11"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle z_{L}^{*}" class="ltx_Math" display="inline" id="S2.Ex11.m1" intent=":literal"><semantics><msubsup><mi>z</mi><mi>L</mi><mo>∗</mo></msubsup><annotation encoding="application/x-tex">\displaystyle z_{L}^{*}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\approx f_{L}\left(z_{L}^{*}+z_{H}+x\right)" class="ltx_Math" display="inline" id="S2.Ex11.m2" intent=":literal"><semantics><mrow><mi></mi><mo>≈</mo><mrow><msub><mi>f</mi><mi>L</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo>(</mo><mrow><msubsup><mi>z</mi><mi>L</mi><mo>∗</mo></msubsup><mo>+</mo><msub><mi>z</mi><mi>H</mi></msub><mo>+</mo><mi>x</mi></mrow><mo>)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\approx f_{L}\left(z_{L}^{*}+z_{H}+x\right)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.Ex12"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle z_{H}^{*}" class="ltx_Math" display="inline" id="S2.Ex12.m1" intent=":literal"><semantics><msubsup><mi>z</mi><mi>H</mi><mo>∗</mo></msubsup><annotation encoding="application/x-tex">\displaystyle z_{H}^{*}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\approx f_{H}\left(z_{L}+z_{H}^{*}\right)," class="ltx_Math" display="inline" id="S2.Ex12.m2" intent=":literal"><semantics><mrow><mrow><mi></mi><mo>≈</mo><mrow><msub><mi>f</mi><mi>H</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo>(</mo><mrow><msub><mi>z</mi><mi>L</mi></msub><mo>+</mo><msubsup><mi>z</mi><mi>H</mi><mo>∗</mo></msubsup></mrow><mo>)</mo></mrow></mrow></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">\displaystyle\approx f_{H}\left(z_{L}+z_{H}^{*}\right),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p">the Implicit Function Theorem <cite class="ltx_cite ltx_citemacro_citep">(Krantz &amp; Parks, <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib17" title="">2002</a>)</cite> with the 1-step gradient approximation <cite class="ltx_cite ltx_citemacro_citep">(Bai et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib3" title="">2019</a>)</cite> is used to approximate the gradient by back-propagating only the last <math alttext="f_{L}" class="ltx_Math" display="inline" id="S2.SS3.p1.m7" intent=":literal"><semantics><msub><mi>f</mi><mi>L</mi></msub><annotation encoding="application/x-tex">f_{L}</annotation></semantics></math> and <math alttext="f_{H}" class="ltx_Math" display="inline" id="S2.SS3.p1.m8" intent=":literal"><semantics><msub><mi>f</mi><mi>H</mi></msub><annotation encoding="application/x-tex">f_{H}</annotation></semantics></math> steps.
This theorem is used to justify only tracking the gradients of the last two steps (out of 6), which greatly reduces memory demands.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Deep supervision</h3>
<div class="ltx_para" id="S2.SS4.p1">
<p class="ltx_p">To improve effective depth, deep supervision is used. This consists of reusing the previous latent features (<math alttext="z_{H}" class="ltx_Math" display="inline" id="S2.SS4.p1.m1" intent=":literal"><semantics><msub><mi>z</mi><mi>H</mi></msub><annotation encoding="application/x-tex">z_{H}</annotation></semantics></math> and <math alttext="z_{L}" class="ltx_Math" display="inline" id="S2.SS4.p1.m2" intent=":literal"><semantics><msub><mi>z</mi><mi>L</mi></msub><annotation encoding="application/x-tex">z_{L}</annotation></semantics></math>) as initialization for the next forward pass. This allows the model to reason over many iterations and improve its latent features (<math alttext="z_{L}" class="ltx_Math" display="inline" id="S2.SS4.p1.m3" intent=":literal"><semantics><msub><mi>z</mi><mi>L</mi></msub><annotation encoding="application/x-tex">z_{L}</annotation></semantics></math> and <math alttext="z_{H}" class="ltx_Math" display="inline" id="S2.SS4.p1.m4" intent=":literal"><semantics><msub><mi>z</mi><mi>H</mi></msub><annotation encoding="application/x-tex">z_{H}</annotation></semantics></math>) until it (hopefully) converges to the correct solution. At most <math alttext="N_{sup}=16" class="ltx_Math" display="inline" id="S2.SS4.p1.m5" intent=":literal"><semantics><mrow><msub><mi>N</mi><mrow><mi>s</mi><mo lspace="0em" rspace="0em">​</mo><mi>u</mi><mo lspace="0em" rspace="0em">​</mo><mi>p</mi></mrow></msub><mo>=</mo><mn>16</mn></mrow><annotation encoding="application/x-tex">N_{sup}=16</annotation></semantics></math> supervision steps are used.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.5 </span>Adaptive computational time (ACT)</h3>
<div class="ltx_para" id="S2.SS5.p1">
<p class="ltx_p">With deep supervision, each mini-batch of data samples must be used for <math alttext="N_{sup}=16" class="ltx_Math" display="inline" id="S2.SS5.p1.m1" intent=":literal"><semantics><mrow><msub><mi>N</mi><mrow><mi>s</mi><mo lspace="0em" rspace="0em">​</mo><mi>u</mi><mo lspace="0em" rspace="0em">​</mo><mi>p</mi></mrow></msub><mo>=</mo><mn>16</mn></mrow><annotation encoding="application/x-tex">N_{sup}=16</annotation></semantics></math> supervision steps before moving to the next mini-batch. This is expensive, and there is a balance to be reached between optimizing a few data examples for many supervision steps versus optimizing many data examples with less supervision steps. To reach a better balance, a halting mechanism is incorporated to determine whether the model should terminate early. It is learned through a Q-learning objective that requires passing the <math alttext="z_{H}" class="ltx_Math" display="inline" id="S2.SS5.p1.m2" intent=":literal"><semantics><msub><mi>z</mi><mi>H</mi></msub><annotation encoding="application/x-tex">z_{H}</annotation></semantics></math> through an additional head and running an additional forward pass (to determine if halting now rather than later would have been preferable). They call this method Adaptive computational time (ACT). It is only used during training, while the full <math alttext="N_{sup}=16" class="ltx_Math" display="inline" id="S2.SS5.p1.m3" intent=":literal"><semantics><mrow><msub><mi>N</mi><mrow><mi>s</mi><mo lspace="0em" rspace="0em">​</mo><mi>u</mi><mo lspace="0em" rspace="0em">​</mo><mi>p</mi></mrow></msub><mo>=</mo><mn>16</mn></mrow><annotation encoding="application/x-tex">N_{sup}=16</annotation></semantics></math> supervision steps are done at test time to maximize downstream performance. ACT greatly diminishes the time spent per example (on average spending less than 2 steps on the Sudoku-Extreme dataset rather than the full <math alttext="N_{sup}=16" class="ltx_Math" display="inline" id="S2.SS5.p1.m4" intent=":literal"><semantics><mrow><msub><mi>N</mi><mrow><mi>s</mi><mo lspace="0em" rspace="0em">​</mo><mi>u</mi><mo lspace="0em" rspace="0em">​</mo><mi>p</mi></mrow></msub><mo>=</mo><mn>16</mn></mrow><annotation encoding="application/x-tex">N_{sup}=16</annotation></semantics></math> steps), allowing more coverage of the dataset given a fixed number of training iterations.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.6 </span>Deep supervision and 1-step gradient approximations replaces BPTT</h3>
<div class="ltx_para" id="S2.SS6.p1">
<p class="ltx_p">Deep supervision and the 1-step gradient approximation provide a more biologically plausible and less computationally-expansive alternative to Backpropagation Through Time (BPTT) <cite class="ltx_cite ltx_citemacro_citep">(Werbos, <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib36" title="">1974</a>; Rumelhart et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib26" title="">1985</a>; LeCun, <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib18" title="">1985</a>)</cite> for solving the temporal credit assignment (TCA) <cite class="ltx_cite ltx_citemacro_citep">(Rumelhart et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib26" title="">1985</a>; Werbos, <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib37" title="">1988</a>; Elman, <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib10" title="">1990</a>)</cite> problem <cite class="ltx_cite ltx_citemacro_citep">(Lillicrap &amp; Santoro, <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib20" title="">2019</a>)</cite>. The implication is that HRM can learn what would normally require an extremely large network without having to back-propagate through its entire depth. Given the hyperparameters used by <cite class="ltx_cite ltx_citemacro_citet">Jang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib14" title="">2023</a>)</cite> in all their experiments, HRM effectively reasons over <math alttext="n_{layers}(n+1)TN_{sup}=4*(2+1)*2*16=384" class="ltx_Math" display="inline" id="S2.SS6.p1.m1" intent=":literal"><semantics><mrow><mrow><msub><mi>n</mi><mrow><mi>l</mi><mo lspace="0em" rspace="0em">​</mo><mi>a</mi><mo lspace="0em" rspace="0em">​</mo><mi>y</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>r</mi><mo lspace="0em" rspace="0em">​</mo><mi>s</mi></mrow></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy="false">)</mo></mrow><mo lspace="0em" rspace="0em">​</mo><mi>T</mi><mo lspace="0em" rspace="0em">​</mo><msub><mi>N</mi><mrow><mi>s</mi><mo lspace="0em" rspace="0em">​</mo><mi>u</mi><mo lspace="0em" rspace="0em">​</mo><mi>p</mi></mrow></msub></mrow><mo>=</mo><mrow><mn>4</mn><mo lspace="0.222em" rspace="0.222em">∗</mo><mrow><mo stretchy="false">(</mo><mrow><mn>2</mn><mo>+</mo><mn>1</mn></mrow><mo rspace="0.055em" stretchy="false">)</mo></mrow><mo rspace="0.222em">∗</mo><mn>2</mn><mo lspace="0.222em" rspace="0.222em">∗</mo><mn>16</mn></mrow><mo>=</mo><mn>384</mn></mrow><annotation encoding="application/x-tex">n_{layers}(n+1)TN_{sup}=4*(2+1)*2*16=384</annotation></semantics></math> layers of effective depth.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS7">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.7 </span>Summary of HRM</h3>
<div class="ltx_para" id="S2.SS7.p1">
<p class="ltx_p">HRM leverages recursion from two networks at different frequencies (high frequency versus low frequency) and deep supervision to learn to improve its answer over multiple supervision steps (with ACT to reduce time spent per data example). This enables the model to imitate extremely large depth without requiring backpropagation through all layers. This approach obtains significantly higher performance on hard question-answer tasks that regular supervised models struggle with. However, this method is quite complicated, relying a bit too heavily on uncertain biological arguments and fixed-point theorems that are not guaranteed to be applicable. In the next section, we discuss those issues and potential targets for improvements in HRM.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Target for improvements in Hierarchical Reasoning Models</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p">In this section, we identify key targets for improvements in HRM, which will be addressed by our proposed method, Tiny Recursion Models (TRMs).</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Implicit Function Theorem (IFT) with 1-step gradient approximation</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p">HRM only back-propagates through the last 2 of the 6 recursions. The authors justify this by leveraging the Implicit Function Theorem (IFT) and one-step approximation, which states that when a recurrent function converges to a fixed point, backpropagation can be applied in a single step at that equilibrium point.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p">There are concerns about applying this theorem to HRM. Most importantly, there is no guarantee that a fixed-point is reached. Deep equilibrium models normally do fixed-point iteration to solve for the fixed point<math alttext="z^{*}=f(z^{*})" class="ltx_Math" display="inline" id="S3.SS1.p2.m1" intent=":literal"><semantics><mrow><msup><mi>z</mi><mo>∗</mo></msup><mo>=</mo><mrow><mi>f</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msup><mi>z</mi><mo>∗</mo></msup><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">z^{*}=f(z^{*})</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_citep">(Bai et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib3" title="">2019</a>)</cite>. However, in the case of HRM, it is not iterating to the fixed-point but simply doing forward passes of <math alttext="f_{L}" class="ltx_Math" display="inline" id="S3.SS1.p2.m2" intent=":literal"><semantics><msub><mi>f</mi><mi>L</mi></msub><annotation encoding="application/x-tex">f_{L}</annotation></semantics></math> and <math alttext="f_{H}" class="ltx_Math" display="inline" id="S3.SS1.p2.m3" intent=":literal"><semantics><msub><mi>f</mi><mi>H</mi></msub><annotation encoding="application/x-tex">f_{H}</annotation></semantics></math>. To make matters worse, HRM is only doing 4 recursions before stopping to apply the one-step approximation. After its first loop of two <math alttext="f_{L}" class="ltx_Math" display="inline" id="S3.SS1.p2.m4" intent=":literal"><semantics><msub><mi>f</mi><mi>L</mi></msub><annotation encoding="application/x-tex">f_{L}</annotation></semantics></math> and 1 <math alttext="f_{H}" class="ltx_Math" display="inline" id="S3.SS1.p2.m5" intent=":literal"><semantics><msub><mi>f</mi><mi>H</mi></msub><annotation encoding="application/x-tex">f_{H}</annotation></semantics></math> evaluations, it only apply a single <math alttext="f_{L}" class="ltx_Math" display="inline" id="S3.SS1.p2.m6" intent=":literal"><semantics><msub><mi>f</mi><mi>L</mi></msub><annotation encoding="application/x-tex">f_{L}</annotation></semantics></math> evaluation before assuming that a fixed-point is reached for both <math alttext="z_{L}" class="ltx_Math" display="inline" id="S3.SS1.p2.m7" intent=":literal"><semantics><msub><mi>z</mi><mi>L</mi></msub><annotation encoding="application/x-tex">z_{L}</annotation></semantics></math> and <math alttext="z_{H}" class="ltx_Math" display="inline" id="S3.SS1.p2.m8" intent=":literal"><semantics><msub><mi>z</mi><mi>H</mi></msub><annotation encoding="application/x-tex">z_{H}</annotation></semantics></math> (<math alttext="z_{L}^{*}=f_{L}(z_{L}^{*}+z_{H}+x)" class="ltx_Math" display="inline" id="S3.SS1.p2.m9" intent=":literal"><semantics><mrow><msubsup><mi>z</mi><mi>L</mi><mo>∗</mo></msubsup><mo>=</mo><mrow><msub><mi>f</mi><mi>L</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><msubsup><mi>z</mi><mi>L</mi><mo>∗</mo></msubsup><mo>+</mo><msub><mi>z</mi><mi>H</mi></msub><mo>+</mo><mi>x</mi></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">z_{L}^{*}=f_{L}(z_{L}^{*}+z_{H}+x)</annotation></semantics></math> and <math alttext="z_{H}^{*}=f_{H}(z_{L}^{*}+z_{H}^{*})" class="ltx_Math" display="inline" id="S3.SS1.p2.m10" intent=":literal"><semantics><mrow><msubsup><mi>z</mi><mi>H</mi><mo>∗</mo></msubsup><mo>=</mo><mrow><msub><mi>f</mi><mi>H</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><msubsup><mi>z</mi><mi>L</mi><mo>∗</mo></msubsup><mo>+</mo><msubsup><mi>z</mi><mi>H</mi><mo>∗</mo></msubsup></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">z_{H}^{*}=f_{H}(z_{L}^{*}+z_{H}^{*})</annotation></semantics></math>). Then, the one-step gradient approximation is applied to both latent variables in succession.</p>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p">The authors justify that a fixed-point is reached by depicting an example with <math alttext="n=7" class="ltx_Math" display="inline" id="S3.SS1.p3.m1" intent=":literal"><semantics><mrow><mi>n</mi><mo>=</mo><mn>7</mn></mrow><annotation encoding="application/x-tex">n=7</annotation></semantics></math> and <math alttext="T=7" class="ltx_Math" display="inline" id="S3.SS1.p3.m2" intent=":literal"><semantics><mrow><mi>T</mi><mo>=</mo><mn>7</mn></mrow><annotation encoding="application/x-tex">T=7</annotation></semantics></math> where the forward residuals is reduced over time (Figure 3 in <cite class="ltx_cite ltx_citemacro_citet">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib34" title="">2025</a>)</cite>). Even in this setting, which is different from the much smaller <math alttext="n=2" class="ltx_Math" display="inline" id="S3.SS1.p3.m3" intent=":literal"><semantics><mrow><mi>n</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">n=2</annotation></semantics></math> and <math alttext="T=2" class="ltx_Math" display="inline" id="S3.SS1.p3.m4" intent=":literal"><semantics><mrow><mi>T</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">T=2</annotation></semantics></math> used in every experiment of their paper, we observe the following:</p>
<ol class="ltx_enumerate" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p">the residual for <math alttext="z_{H}" class="ltx_Math" display="inline" id="S3.I1.i1.p1.m1" intent=":literal"><semantics><msub><mi>z</mi><mi>H</mi></msub><annotation encoding="application/x-tex">z_{H}</annotation></semantics></math> is clearly well above 0 at every step</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p">the residual for <math alttext="z_{L}" class="ltx_Math" display="inline" id="S3.I1.i2.p1.m1" intent=":literal"><semantics><msub><mi>z</mi><mi>L</mi></msub><annotation encoding="application/x-tex">z_{L}</annotation></semantics></math> only becomes closer to 0 after many cycles, but it remains significantly above 0</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p"><math alttext="z_{L}" class="ltx_Math" display="inline" id="S3.I1.i3.p1.m1" intent=":literal"><semantics><msub><mi>z</mi><mi>L</mi></msub><annotation encoding="application/x-tex">z_{L}</annotation></semantics></math> is very far from converged after one <math alttext="f_{L}" class="ltx_Math" display="inline" id="S3.I1.i3.p1.m2" intent=":literal"><semantics><msub><mi>f</mi><mi>L</mi></msub><annotation encoding="application/x-tex">f_{L}</annotation></semantics></math> evaluation at <math alttext="T" class="ltx_Math" display="inline" id="S3.I1.i3.p1.m3" intent=":literal"><semantics><mi>T</mi><annotation encoding="application/x-tex">T</annotation></semantics></math> cycles, which is when the fixed-point is assumed to be reached and the 1-step gradient approximation is used</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S3.SS1.p4">
<p class="ltx_p">Thus, while the application of the IFT theorem and 1-step gradient approximation to HRM has some basis since the residuals do generally reduce over time, a fixed point is unlikely to be reached when the theorem is actually applied.</p>
</div>
<div class="ltx_para" id="S3.SS1.p5">
<p class="ltx_p">In the next section, we show that we can bypass the need for the IFT theorem and 1-step gradient approximation, thus bypassing the issue entirely.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Twice the forward passes with Adaptive computational time (ACT)</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p">HRM uses Adaptive computational time (ACT) during training to optimize the time spent of each data sample. Without ACT, <math alttext="N_{sup}=16" class="ltx_Math" display="inline" id="S3.SS2.p1.m1" intent=":literal"><semantics><mrow><msub><mi>N</mi><mrow><mi>s</mi><mo lspace="0em" rspace="0em">​</mo><mi>u</mi><mo lspace="0em" rspace="0em">​</mo><mi>p</mi></mrow></msub><mo>=</mo><mn>16</mn></mrow><annotation encoding="application/x-tex">N_{sup}=16</annotation></semantics></math> supervision steps would be spent on the same data sample, which is highly inefficient. They implement ACT through an additional Q-learning objective, which decides when to halt and move to a new data sample rather than keep iterating on the same data. This allows much more efficient use of time especially since the average number of supervision steps during training is quite low with ACT (less than 2 steps on the Sudoku-Extreme dataset as per their reported numbers).</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p">However, ACT comes at a cost. This cost is not directly shown in the HRM’s paper, but it is shown in their official code. The Q-learning objective relies on a halting loss and a continue loss. The continue loss requires an extra forward pass through HRM (with all 6 function evaluations). This means that while ACT optimizes time more efficiently per sample, it requires 2 forward passes per optimization step. The exact formulation is shown in Algorithm <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S2.F2" title="Figure 2 ‣ 2.1 Structure and goal ‣ 2 Background ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p">In the next section, we show that we can bypass the need for two forward passes in ACT.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Hierarchical interpretation based on complex biological arguments</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p">The HRM’s authors justify the two latent variables and two networks operating at different hierarchies based on biological arguments, which are very far from artificial neural networks. They even try to match HRM to actual brain experiments on mice. While interesting, this sort of explanation makes it incredibly hard to parse out why HRM is designed the way it is. Given the lack of ablation table in their paper, the over-reliance on biological arguments and fixed-point theorems (that are not perfectly applicable), it is hard to determine what parts of HRM is helping what and why. Furthermore, it is not clear why they use two latent features rather than other combinations of features.</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p">In the next section, we show that the recursive process can be greatly simplified and understood in a much simpler manner that does not require any biological argument, fixed-point theorem, hierarchical interpretation, nor using two networks. It also explains why 2 is the optimal number of features (<math alttext="z_{L}" class="ltx_Math" display="inline" id="S3.SS3.p2.m1" intent=":literal"><semantics><msub><mi>z</mi><mi>L</mi></msub><annotation encoding="application/x-tex">z_{L}</annotation></semantics></math> and <math alttext="z_{H}" class="ltx_Math" display="inline" id="S3.SS3.p2.m2" intent=":literal"><semantics><msub><mi>z</mi><mi>H</mi></msub><annotation encoding="application/x-tex">z_{H}</annotation></semantics></math>).</p>
</div>
<figure class="ltx_figure" id="S3.F3">
<div class="ltx_listing ltx_lst_language_python ltx_lstlisting ltx_align_center ltx_listing" style="--ltx-bg-color:#FFFFFF;">
<div class="ltx_listing_data"><a download="" href="data:text/plain;base64,CmRlZiBsYXRlbnRfcmVjdXJzaW9uKHgsIHksIHosIG49Nik6CiAgICBmb3IgaSBpbiByYW5nZShuKTogIyBsYXRlbnQgcmVhc29uaW5nCiAgICAgICAgeiA9IG5ldCh4LCB5LCB6KQogICAgeSA9IG5ldCh5LCB6KSAjIHJlZmluZSBvdXRwdXQgYW5zd2VyCiAgICByZXR1cm4geSwgegoKZGVmIGRlZXBfcmVjdXJzaW9uKHgsIHksIHosIG49NiwgVD0zKToKICAgICMgcmVjdXJzaW5nIFQtMSB0aW1lcyB0byBpbXByb3ZlIHkgYW5kIHogKG5vIGdyYWRpZW50cyBuZWVkZWQpCiAgICB3aXRoIHRvcmNoLm5vX2dyYWQoKToKICAgICAgICBmb3IgaiBpbiByYW5nZShULTEpOgogICAgICAgICAgICB5LCB6ID0gbGF0ZW50X3JlY3Vyc2lvbih4LCB5LCB6LCBuKQogICAgIyByZWN1cnNpbmcgb25jZSB0byBpbXByb3ZlIHkgYW5kIHoKICAgIHksIHogPSBsYXRlbnRfcmVjdXJzaW9uKHgsIHksIHosIG4pCiAgICByZXR1cm4gKHkuZGV0YWNoKCksIHouZGV0YWNoKCkpLCBvdXRwdXRfaGVhZCh5KSwgUV9oZWFkKHkpCgojIERlZXAgU3VwZXJ2aXNpb24KZm9yIHhfaW5wdXQsIHlfdHJ1ZSBpbiB0cmFpbl9kYXRhbG9hZGVyOgogICAgeSwgeiA9IHlfaW5pdCwgel9pbml0CiAgICBmb3Igc3RlcCBpbiByYW5nZShOX3N1cGVydmlzaW9uKToKICAgICAgICB4ID0gaW5wdXRfZW1iZWRkaW5nKHhfaW5wdXQpCiAgICAgICAgKHksIHopLCB5X2hhdCwgcV9oYXQgPSBkZWVwX3JlY3Vyc2lvbih4LCB5LCB6KQogICAgICAgIGxvc3MgPSBzb2Z0bWF4X2Nyb3NzX2VudHJvcHkoeV9oYXQsIHlfdHJ1ZSkKICAgICAgICBsb3NzICs9IGJpbmFyeV9jcm9zc19lbnRyb3B5KHFfaGF0LCAoeV9oYXQgPT0geV90cnVlKSkKICAgICAgICBsb3NzLmJhY2t3YXJkKCkKICAgICAgICBvcHQuc3RlcCgpCiAgICAgICAgb3B0Lnplcm9fZ3JhZCgpCiAgICAgICAgaWYgcV9oYXQgPiAwOiAjIGVhcmx5LXN0b3BwaW5nCiAgICAgICAgICAgIGJyZWFr">⬇</a></div>
<div class="ltx_listingline" id="lstnumberx43">
</div>
<div class="ltx_listingline" id="lstnumberx44">
<span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">def</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">latent_recursion</span>(<span class="ltx_text ltx_lst_identifier">x</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">n</span>=6):
</div>
<div class="ltx_listingline" id="lstnumberx45">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">for</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">i</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">in</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword ltx_lst_keywords2" style="--ltx-fg-color:#0000FF;">range</span>(<span class="ltx_text ltx_lst_identifier">n</span>):<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_comment" style="--ltx-fg-color:#808080;">#<span class="ltx_text ltx_lst_space"> </span>latent<span class="ltx_text ltx_lst_space"> </span>reasoning</span>
</div>
<div class="ltx_listingline" id="lstnumberx46">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">net</span>(<span class="ltx_text ltx_lst_identifier">x</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>)
</div>
<div class="ltx_listingline" id="lstnumberx47">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">net</span>(<span class="ltx_text ltx_lst_identifier">y</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>)<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_comment" style="--ltx-fg-color:#808080;">#<span class="ltx_text ltx_lst_space"> </span>refine<span class="ltx_text ltx_lst_space"> </span>output<span class="ltx_text ltx_lst_space"> </span>answer</span>
</div>
<div class="ltx_listingline" id="lstnumberx48">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">return</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>
</div>
<div class="ltx_listingline" id="lstnumberx49">
</div>
<div class="ltx_listingline" id="lstnumberx50">
<span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">def</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">deep_recursion</span>(<span class="ltx_text ltx_lst_identifier">x</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">n</span>=6,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">T</span>=3):
</div>
<div class="ltx_listingline" id="lstnumberx51">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_comment" style="--ltx-fg-color:#808080;">#<span class="ltx_text ltx_lst_space"> </span>recursing<span class="ltx_text ltx_lst_space"> </span>T-1<span class="ltx_text ltx_lst_space"> </span>times<span class="ltx_text ltx_lst_space"> </span>to<span class="ltx_text ltx_lst_space"> </span>improve<span class="ltx_text ltx_lst_space"> </span>y<span class="ltx_text ltx_lst_space"> </span>and<span class="ltx_text ltx_lst_space"> </span>z<span class="ltx_text ltx_lst_space"> </span>(no<span class="ltx_text ltx_lst_space"> </span>gradients<span class="ltx_text ltx_lst_space"> </span>needed)</span>
</div>
<div class="ltx_listingline" id="lstnumberx52">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">with</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">torch</span>.<span class="ltx_text ltx_lst_identifier">no_grad</span>():
</div>
<div class="ltx_listingline" id="lstnumberx53">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">for</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">j</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">in</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword ltx_lst_keywords2" style="--ltx-fg-color:#0000FF;">range</span>(<span class="ltx_text ltx_lst_identifier">T</span>-1):
</div>
<div class="ltx_listingline" id="lstnumberx54">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">latent_recursion</span>(<span class="ltx_text ltx_lst_identifier">x</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">n</span>)
</div>
<div class="ltx_listingline" id="lstnumberx55">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_comment" style="--ltx-fg-color:#808080;">#<span class="ltx_text ltx_lst_space"> </span>recursing<span class="ltx_text ltx_lst_space"> </span>once<span class="ltx_text ltx_lst_space"> </span>to<span class="ltx_text ltx_lst_space"> </span>improve<span class="ltx_text ltx_lst_space"> </span>y<span class="ltx_text ltx_lst_space"> </span>and<span class="ltx_text ltx_lst_space"> </span>z</span>
</div>
<div class="ltx_listingline" id="lstnumberx56">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">latent_recursion</span>(<span class="ltx_text ltx_lst_identifier">x</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">n</span>)
</div>
<div class="ltx_listingline" id="lstnumberx57">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">return</span><span class="ltx_text ltx_lst_space"> </span>(<span class="ltx_text ltx_lst_identifier">y</span>.<span class="ltx_text ltx_lst_identifier">detach</span>(),<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>.<span class="ltx_text ltx_lst_identifier">detach</span>()),<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">output_head</span>(<span class="ltx_text ltx_lst_identifier">y</span>),<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">Q_head</span>(<span class="ltx_text ltx_lst_identifier">y</span>)
</div>
<div class="ltx_listingline" id="lstnumberx58">
</div>
<div class="ltx_listingline" id="lstnumberx59">
<span class="ltx_text ltx_lst_comment" style="--ltx-fg-color:#808080;">#<span class="ltx_text ltx_lst_space"> </span>Deep<span class="ltx_text ltx_lst_space"> </span>Supervision</span>
</div>
<div class="ltx_listingline" id="lstnumberx60">
<span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">for</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">x_input</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y_true</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">in</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">train_dataloader</span>:
</div>
<div class="ltx_listingline" id="lstnumberx61">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y_init</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z_init</span>
</div>
<div class="ltx_listingline" id="lstnumberx62">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">for</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">step</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">in</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword ltx_lst_keywords2" style="--ltx-fg-color:#0000FF;">range</span>(<span class="ltx_text ltx_lst_identifier">N_supervision</span>):
</div>
<div class="ltx_listingline" id="lstnumberx63">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">x</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">input_embedding</span>(<span class="ltx_text ltx_lst_identifier">x_input</span>)
</div>
<div class="ltx_listingline" id="lstnumberx64">
<span class="ltx_text ltx_lst_space"> </span>(<span class="ltx_text ltx_lst_identifier">y</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>),<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y_hat</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">q_hat</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">deep_recursion</span>(<span class="ltx_text ltx_lst_identifier">x</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>)
</div>
<div class="ltx_listingline" id="lstnumberx65">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">loss</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">softmax_cross_entropy</span>(<span class="ltx_text ltx_lst_identifier">y_hat</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y_true</span>)
</div>
<div class="ltx_listingline" id="lstnumberx66">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">loss</span><span class="ltx_text ltx_lst_space"> </span>+=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">binary_cross_entropy</span>(<span class="ltx_text ltx_lst_identifier">q_hat</span>,<span class="ltx_text ltx_lst_space"> </span>(<span class="ltx_text ltx_lst_identifier">y_hat</span><span class="ltx_text ltx_lst_space"> </span>==<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y_true</span>))
</div>
<div class="ltx_listingline" id="lstnumberx67">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">loss</span>.<span class="ltx_text ltx_lst_identifier">backward</span>()
</div>
<div class="ltx_listingline" id="lstnumberx68">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">opt</span>.<span class="ltx_text ltx_lst_identifier">step</span>()
</div>
<div class="ltx_listingline" id="lstnumberx69">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">opt</span>.<span class="ltx_text ltx_lst_identifier">zero_grad</span>()
</div>
<div class="ltx_listingline" id="lstnumberx70">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">if</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">q_hat</span><span class="ltx_text ltx_lst_space"> </span>&gt;<span class="ltx_text ltx_lst_space"> </span>0:<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_comment" style="--ltx-fg-color:#808080;">#<span class="ltx_text ltx_lst_space"> </span>early-stopping</span>
</div>
<div class="ltx_listingline" id="lstnumberx71">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">break</span>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Pseudocode of Tiny Recursion Models (TRMs).</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Tiny Recursion Models</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p">In this section, we present Tiny Recursion Models (TRMs). Contrary to HRM, TRM requires no complex mathematical theorem, hierarchy, nor biological arguments. It generalizes better while requiring only a single tiny network (instead of two medium-size networks) and a single forward pass for the ACT (instead of 2 passes). Our approach is described in Algorithm <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S3.F3" title="Figure 3 ‣ 3.3 Hierarchical interpretation based on complex biological arguments ‣ 3 Target for improvements in Hierarchical Reasoning Models ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_tag">3</span></a> and illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_tag">1</span></a>. We also provide an ablation in Table <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S4.T1" title="Table 1 ‣ 4 Tiny Recursion Models ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_tag">1</span></a> on the Sudoku-Extreme dataset (a dataset of difficult Sudokus with only 1K training examples, but 423K test examples). Below, we explain the key components of TRMs.</p>
</div>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Ablation of TRM on Sudoku-Extreme comparing % Test accuracy, effective depth per supervision step <math alttext="(T(n+1)n_{layers})" class="ltx_Math" display="inline" id="S4.T1.m2" intent=":literal"><semantics><mrow><mo stretchy="false">(</mo><mrow><mi>T</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy="false">)</mo></mrow><mo lspace="0em" rspace="0em">​</mo><msub><mi>n</mi><mrow><mi>l</mi><mo lspace="0em" rspace="0em">​</mo><mi>a</mi><mo lspace="0em" rspace="0em">​</mo><mi>y</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>r</mi><mo lspace="0em" rspace="0em">​</mo><mi>s</mi></mrow></msub></mrow><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(T(n+1)n_{layers})</annotation></semantics></math>, number of Forward Passes (NFP) per optimization step, and number of parameters</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">Method</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">Acc (%)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">Depth</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">NFP</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"># Params</th>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">HRM</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">55.0</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">24</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">2</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">27M</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">TRM (<math alttext="T=3,n=6" class="ltx_Math" display="inline" id="S4.T1.m3" intent=":literal"><semantics><mrow><mrow><mi>T</mi><mo>=</mo><mn>3</mn></mrow><mo>,</mo><mrow><mi>n</mi><mo>=</mo><mn>6</mn></mrow></mrow><annotation encoding="application/x-tex">T=3,n=6</annotation></semantics></math>)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">87.4</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">42</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">1</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">5M</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">w/ ACT</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">86.1</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">42</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">2</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">5M</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">w/ separate <math alttext="f_{H},f_{L}" class="ltx_Math" display="inline" id="S4.T1.m4" intent=":literal"><semantics><mrow><msub><mi>f</mi><mi>H</mi></msub><mo>,</mo><msub><mi>f</mi><mi>L</mi></msub></mrow><annotation encoding="application/x-tex">f_{H},f_{L}</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">82.4</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">42</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">1</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">10M</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">no EMA</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">79.9</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">42</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">1</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">5M</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">w/ 4-layers, <math alttext="n=3" class="ltx_Math" display="inline" id="S4.T1.m5" intent=":literal"><semantics><mrow><mi>n</mi><mo>=</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">n=3</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">79.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">48</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">1</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">10M</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">w/ self-attention</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">74.7</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">42</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">1</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">7M</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">w/ <math alttext="T=2,n=2" class="ltx_Math" display="inline" id="S4.T1.m6" intent=":literal"><semantics><mrow><mrow><mi>T</mi><mo>=</mo><mn>2</mn></mrow><mo>,</mo><mrow><mi>n</mi><mo>=</mo><mn>2</mn></mrow></mrow><annotation encoding="application/x-tex">T=2,n=2</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">73.7</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">12</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">1</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">5M</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">w/ 1-step gradient</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">56.5</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">42</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">1</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">5M</td>
</tr>
</tbody>
</table>
</figure>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>No fixed-point theorem required</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p">HRM assumes that the recursions converge to a fixed-point for both <math alttext="z_{L}" class="ltx_Math" display="inline" id="S4.SS1.p1.m1" intent=":literal"><semantics><msub><mi>z</mi><mi>L</mi></msub><annotation encoding="application/x-tex">z_{L}</annotation></semantics></math> and <math alttext="z_{H}" class="ltx_Math" display="inline" id="S4.SS1.p1.m2" intent=":literal"><semantics><msub><mi>z</mi><mi>H</mi></msub><annotation encoding="application/x-tex">z_{H}</annotation></semantics></math> in order to leverage the 1-step gradient approximation <cite class="ltx_cite ltx_citemacro_citep">(Bai et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib3" title="">2019</a>)</cite>. This allows the authors to justify only back-propagating through the last two function evaluations (1 <math alttext="f_{L}" class="ltx_Math" display="inline" id="S4.SS1.p1.m3" intent=":literal"><semantics><msub><mi>f</mi><mi>L</mi></msub><annotation encoding="application/x-tex">f_{L}</annotation></semantics></math> and 1 <math alttext="f_{H}" class="ltx_Math" display="inline" id="S4.SS1.p1.m4" intent=":literal"><semantics><msub><mi>f</mi><mi>H</mi></msub><annotation encoding="application/x-tex">f_{H}</annotation></semantics></math>). To bypass this theoretical requirement, we define a full recursion process as containing <math alttext="n" class="ltx_Math" display="inline" id="S4.SS1.p1.m5" intent=":literal"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math> evaluations of <math alttext="f_{L}" class="ltx_Math" display="inline" id="S4.SS1.p1.m6" intent=":literal"><semantics><msub><mi>f</mi><mi>L</mi></msub><annotation encoding="application/x-tex">f_{L}</annotation></semantics></math> and 1 evaluation of <math alttext="f_{H}" class="ltx_Math" display="inline" id="S4.SS1.p1.m7" intent=":literal"><semantics><msub><mi>f</mi><mi>H</mi></msub><annotation encoding="application/x-tex">f_{H}</annotation></semantics></math>:</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="Ax4.EGx3">
<tbody id="S4.Ex13"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle z_{L}" class="ltx_Math" display="inline" id="S4.Ex13.m1" intent=":literal"><semantics><msub><mi>z</mi><mi>L</mi></msub><annotation encoding="application/x-tex">\displaystyle z_{L}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\leftarrow f_{L}\left(z_{L}+z_{H}+x\right)" class="ltx_Math" display="inline" id="S4.Ex13.m2" intent=":literal"><semantics><mrow><mi></mi><mo stretchy="false">←</mo><mrow><msub><mi>f</mi><mi>L</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo>(</mo><mrow><msub><mi>z</mi><mi>L</mi></msub><mo>+</mo><msub><mi>z</mi><mi>H</mi></msub><mo>+</mo><mi>x</mi></mrow><mo>)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\leftarrow f_{L}\left(z_{L}+z_{H}+x\right)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S4.Ex14"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle..." class="ltx_Math" display="inline" id="S4.Ex14.m1" intent=":literal"><semantics><mi mathvariant="normal">…</mi><annotation encoding="application/x-tex">\displaystyle...</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S4.Ex15"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle z_{L}" class="ltx_Math" display="inline" id="S4.Ex15.m1" intent=":literal"><semantics><msub><mi>z</mi><mi>L</mi></msub><annotation encoding="application/x-tex">\displaystyle z_{L}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\leftarrow f_{L}\left(z_{L}+z_{H}+x\right)" class="ltx_Math" display="inline" id="S4.Ex15.m2" intent=":literal"><semantics><mrow><mi></mi><mo stretchy="false">←</mo><mrow><msub><mi>f</mi><mi>L</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo>(</mo><mrow><msub><mi>z</mi><mi>L</mi></msub><mo>+</mo><msub><mi>z</mi><mi>H</mi></msub><mo>+</mo><mi>x</mi></mrow><mo>)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\leftarrow f_{L}\left(z_{L}+z_{H}+x\right)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S4.Ex16"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle z_{H}" class="ltx_Math" display="inline" id="S4.Ex16.m1" intent=":literal"><semantics><msub><mi>z</mi><mi>H</mi></msub><annotation encoding="application/x-tex">\displaystyle z_{H}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\leftarrow f_{H}\left(z_{L}+z_{H}\right)." class="ltx_Math" display="inline" id="S4.Ex16.m2" intent=":literal"><semantics><mrow><mrow><mi></mi><mo stretchy="false">←</mo><mrow><msub><mi>f</mi><mi>H</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo>(</mo><mrow><msub><mi>z</mi><mi>L</mi></msub><mo>+</mo><msub><mi>z</mi><mi>H</mi></msub></mrow><mo>)</mo></mrow></mrow></mrow><mo lspace="0em">.</mo></mrow><annotation encoding="application/x-tex">\displaystyle\leftarrow f_{H}\left(z_{L}+z_{H}\right).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p">Then, we simply back-propagate through the full recursion process.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p">Through deep supervision, the models learns to take any <math alttext="(z_{L},z_{H})" class="ltx_Math" display="inline" id="S4.SS1.p2.m1" intent=":literal"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>z</mi><mi>L</mi></msub><mo>,</mo><msub><mi>z</mi><mi>H</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(z_{L},z_{H})</annotation></semantics></math> and improve it through a full recursion process, hopefully making <math alttext="z_{H}" class="ltx_Math" display="inline" id="S4.SS1.p2.m2" intent=":literal"><semantics><msub><mi>z</mi><mi>H</mi></msub><annotation encoding="application/x-tex">z_{H}</annotation></semantics></math> closer to the solution. This means that by the design of the deep supervision goal, running a few full recursion processes (even without gradients) is expected to bring us closer to the solution. We propose to run <math alttext="T-1" class="ltx_Math" display="inline" id="S4.SS1.p2.m3" intent=":literal"><semantics><mrow><mi>T</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">T-1</annotation></semantics></math> recursion processes without gradient to improve <math alttext="(z_{L},z_{H})" class="ltx_Math" display="inline" id="S4.SS1.p2.m4" intent=":literal"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>z</mi><mi>L</mi></msub><mo>,</mo><msub><mi>z</mi><mi>H</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(z_{L},z_{H})</annotation></semantics></math> before running one recursion process with backpropagation.</p>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p">Thus, instead of using the 1-step gradient approximation, we apply a full recursion process containing <math alttext="n" class="ltx_Math" display="inline" id="S4.SS1.p3.m1" intent=":literal"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math> evaluations of <math alttext="f_{L}" class="ltx_Math" display="inline" id="S4.SS1.p3.m2" intent=":literal"><semantics><msub><mi>f</mi><mi>L</mi></msub><annotation encoding="application/x-tex">f_{L}</annotation></semantics></math> and 1 evaluation of <math alttext="f_{H}" class="ltx_Math" display="inline" id="S4.SS1.p3.m3" intent=":literal"><semantics><msub><mi>f</mi><mi>H</mi></msub><annotation encoding="application/x-tex">f_{H}</annotation></semantics></math>. This removes entirely the need to assume that a fixed-point is reached and the use of the IFT theorem with 1-step gradient approximation. Yet, we can still leverage multiple backpropagation-free recursion processes to improve <math alttext="(z_{L},z_{H})" class="ltx_Math" display="inline" id="S4.SS1.p3.m4" intent=":literal"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>z</mi><mi>L</mi></msub><mo>,</mo><msub><mi>z</mi><mi>H</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(z_{L},z_{H})</annotation></semantics></math>. With this approach, we obtain a massive boost in generalization on Sudoku-Extreme (improving TRM from 56.5% to 87.4%; see Table 1).</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Simpler reinterpretation of <math alttext="z_{H}" class="ltx_Math" display="inline" id="S4.SS2.m1" intent=":literal"><semantics><msub><mi>z</mi><mi>H</mi></msub><annotation encoding="application/x-tex">z_{H}</annotation></semantics></math> and <math alttext="z_{L}" class="ltx_Math" display="inline" id="S4.SS2.m2" intent=":literal"><semantics><msub><mi>z</mi><mi>L</mi></msub><annotation encoding="application/x-tex">z_{L}</annotation></semantics></math>
</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p">HRM is interpreted as doing hierarchical reasoning over two latent features of different hierarchies due to arguments from biology. However, one might wonder why use two latent features instead of 1, 3, or more? And do we really need to justify these so-called ”hierarchical” features based on biology to make sense of them? We propose a simple non-biological explanation, which is more natural, and directly answers the question of why there are 2 features.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p">The fact of the matter is: <math alttext="z_{H}" class="ltx_Math" display="inline" id="S4.SS2.p2.m1" intent=":literal"><semantics><msub><mi>z</mi><mi>H</mi></msub><annotation encoding="application/x-tex">z_{H}</annotation></semantics></math> is simply the current (embedded) solution. The embedding is reversed by applying the output head and rounding to the nearest token using the argmax operation. On the other hand, <math alttext="z_{L}" class="ltx_Math" display="inline" id="S4.SS2.p2.m2" intent=":literal"><semantics><msub><mi>z</mi><mi>L</mi></msub><annotation encoding="application/x-tex">z_{L}</annotation></semantics></math> is a latent feature that does not directly correspond to a solution, but it can be transformed into a solution by applying <math alttext="z_{H}\leftarrow f_{H}(x,z_{L},z_{H})" class="ltx_Math" display="inline" id="S4.SS2.p2.m3" intent=":literal"><semantics><mrow><msub><mi>z</mi><mi>H</mi></msub><mo stretchy="false">←</mo><mrow><msub><mi>f</mi><mi>H</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><msub><mi>z</mi><mi>L</mi></msub><mo>,</mo><msub><mi>z</mi><mi>H</mi></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">z_{H}\leftarrow f_{H}(x,z_{L},z_{H})</annotation></semantics></math>. We show an example on Sudoku-Extreme in Figure <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#Ax4.F6" title="Figure 6 ‣ Example on Sudoku-Extreme ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_tag">6</span></a> to highlight the fact that <math alttext="z_{H}" class="ltx_Math" display="inline" id="S4.SS2.p2.m4" intent=":literal"><semantics><msub><mi>z</mi><mi>H</mi></msub><annotation encoding="application/x-tex">z_{H}</annotation></semantics></math> does correspond to the solution, but <math alttext="z_{L}" class="ltx_Math" display="inline" id="S4.SS2.p2.m5" intent=":literal"><semantics><msub><mi>z</mi><mi>L</mi></msub><annotation encoding="application/x-tex">z_{L}</annotation></semantics></math> does not.</p>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p">Once this is understood, hierarchy is not needed; there is simply an input <math alttext="x" class="ltx_Math" display="inline" id="S4.SS2.p3.m1" intent=":literal"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math>, a proposed solution <math alttext="y" class="ltx_Math" display="inline" id="S4.SS2.p3.m2" intent=":literal"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math> (previously called <math alttext="z_{H}" class="ltx_Math" display="inline" id="S4.SS2.p3.m3" intent=":literal"><semantics><msub><mi>z</mi><mi>H</mi></msub><annotation encoding="application/x-tex">z_{H}</annotation></semantics></math>), and a latent reasoning feature <math alttext="z" class="ltx_Math" display="inline" id="S4.SS2.p3.m4" intent=":literal"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math> (previously called <math alttext="z_{L}" class="ltx_Math" display="inline" id="S4.SS2.p3.m5" intent=":literal"><semantics><msub><mi>z</mi><mi>L</mi></msub><annotation encoding="application/x-tex">z_{L}</annotation></semantics></math>). Given the input question <math alttext="x" class="ltx_Math" display="inline" id="S4.SS2.p3.m6" intent=":literal"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math>, current solution <math alttext="y" class="ltx_Math" display="inline" id="S4.SS2.p3.m7" intent=":literal"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>, and current latent reasoning <math alttext="z" class="ltx_Math" display="inline" id="S4.SS2.p3.m8" intent=":literal"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math>, the model recursively improves its latent <math alttext="z" class="ltx_Math" display="inline" id="S4.SS2.p3.m9" intent=":literal"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math>. Then, given the current latent <math alttext="z" class="ltx_Math" display="inline" id="S4.SS2.p3.m10" intent=":literal"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math> and the previous solution <math alttext="y" class="ltx_Math" display="inline" id="S4.SS2.p3.m11" intent=":literal"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>, the model proposes a new solution <math alttext="y" class="ltx_Math" display="inline" id="S4.SS2.p3.m12" intent=":literal"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math> (or stay at the current solution if its already good).</p>
</div>
<div class="ltx_para" id="S4.SS2.p4">
<p class="ltx_p">Although this has no direct influence on the algorithm, this re-interpretation is much simpler and natural. It answers the question about why two features: remembering in context the question <math alttext="x" class="ltx_Math" display="inline" id="S4.SS2.p4.m1" intent=":literal"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math>, previous reasoning <math alttext="z" class="ltx_Math" display="inline" id="S4.SS2.p4.m2" intent=":literal"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math>, and previous answer <math alttext="y" class="ltx_Math" display="inline" id="S4.SS2.p4.m3" intent=":literal"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math> helps the model iterate on the next reasoning <math alttext="z" class="ltx_Math" display="inline" id="S4.SS2.p4.m4" intent=":literal"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math> and then the next answer <math alttext="y" class="ltx_Math" display="inline" id="S4.SS2.p4.m5" intent=":literal"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>. If we were not passing the previous reasoning <math alttext="z" class="ltx_Math" display="inline" id="S4.SS2.p4.m6" intent=":literal"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math>, the model would forget how it got to the previous solution <math alttext="y" class="ltx_Math" display="inline" id="S4.SS2.p4.m7" intent=":literal"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math> (since <math alttext="z" class="ltx_Math" display="inline" id="S4.SS2.p4.m8" intent=":literal"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math> acts similarly as a chain-of-thought). If we were not passing the previous solution <math alttext="y" class="ltx_Math" display="inline" id="S4.SS2.p4.m9" intent=":literal"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>, then the model would forget what solution it had and would be forced to store the solution <math alttext="y" class="ltx_Math" display="inline" id="S4.SS2.p4.m10" intent=":literal"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math> within <math alttext="z" class="ltx_Math" display="inline" id="S4.SS2.p4.m11" intent=":literal"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math> instead of using it for latent reasoning. Thus, we need both <math alttext="y" class="ltx_Math" display="inline" id="S4.SS2.p4.m12" intent=":literal"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math> and <math alttext="z" class="ltx_Math" display="inline" id="S4.SS2.p4.m13" intent=":literal"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math> separately, and there is no apparent reason why one would need to split <math alttext="z" class="ltx_Math" display="inline" id="S4.SS2.p4.m14" intent=":literal"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math> into multiple features.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_para" id="S4.SS2.p5">
<p class="ltx_p">While this is intuitive, we wanted to verify whether using more or less features could be helpful. Results are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S4.T2" title="Table 2 ‣ 4.2 Simpler reinterpretation of 𝑧_𝐻 and 𝑧_𝐿 ‣ 4 Tiny Recursion Models ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div class="ltx_para" id="S4.SS2.p6">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">More features</span> (<math alttext="&gt;2" class="ltx_Math" display="inline" id="S4.SS2.p6.m1" intent=":literal"><semantics><mrow><mi></mi><mo>&gt;</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">&gt;2</annotation></semantics></math>): We tested splitting <math alttext="z" class="ltx_Math" display="inline" id="S4.SS2.p6.m2" intent=":literal"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math> into different features by treating each of the <math alttext="n" class="ltx_Math" display="inline" id="S4.SS2.p6.m3" intent=":literal"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math> recursions as producing a different <math alttext="z_{i}" class="ltx_Math" display="inline" id="S4.SS2.p6.m4" intent=":literal"><semantics><msub><mi>z</mi><mi>i</mi></msub><annotation encoding="application/x-tex">z_{i}</annotation></semantics></math> for <math alttext="i=1,...,n" class="ltx_Math" display="inline" id="S4.SS2.p6.m5" intent=":literal"><semantics><mrow><mi>i</mi><mo>=</mo><mrow><mn>1</mn><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><mi>n</mi></mrow></mrow><annotation encoding="application/x-tex">i=1,...,n</annotation></semantics></math>. Then, each <math alttext="z_{i}" class="ltx_Math" display="inline" id="S4.SS2.p6.m6" intent=":literal"><semantics><msub><mi>z</mi><mi>i</mi></msub><annotation encoding="application/x-tex">z_{i}</annotation></semantics></math> is carried across supervision steps. The approach is described in Algorithm <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#Ax3.F5" title="Figure 5 ‣ Algorithms with different number of latent features ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_tag">5</span></a>. In doing so, we found performance to drop. This is expected because, as discussed, there is no apparent need for splitting <math alttext="z" class="ltx_Math" display="inline" id="S4.SS2.p6.m7" intent=":literal"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math> into multiple parts. It does not have to be hierarchical.</p>
</div>
<div class="ltx_para" id="S4.SS2.p7">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Single feature</span>: Similarly, we tested the idea of taking a single feature by only carrying <math alttext="z_{H}" class="ltx_Math" display="inline" id="S4.SS2.p7.m1" intent=":literal"><semantics><msub><mi>z</mi><mi>H</mi></msub><annotation encoding="application/x-tex">z_{H}</annotation></semantics></math> across supervision steps. The approach is described in Algorithm <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#Ax3.F4" title="Figure 4 ‣ Algorithms with different number of latent features ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_tag">4</span></a>. In doing so, we found performance to drop. This is expected because, as discussed, it forces the model to store the solution <math alttext="y" class="ltx_Math" display="inline" id="S4.SS2.p7.m2" intent=":literal"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math> within <math alttext="z" class="ltx_Math" display="inline" id="S4.SS2.p7.m3" intent=":literal"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S4.SS2.p8">
<p class="ltx_p">Thus, we explored using more or less latent variables on Sudoku-Extreme, but found that having only <math alttext="y" class="ltx_Math" display="inline" id="S4.SS2.p8.m1" intent=":literal"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math> and <math alttext="z" class="ltx_Math" display="inline" id="S4.SS2.p8.m2" intent=":literal"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math> lead to better test accuracy in addition to being the simplest more natural approach.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>TRM on Sudoku-Extreme comparing % Test accuracy when using more or less latent features</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">Method</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"># of features</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Acc (%)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">TRM <math alttext="y,z" class="ltx_Math" display="inline" id="S4.T2.m1" intent=":literal"><semantics><mrow><mi>y</mi><mo>,</mo><mi>z</mi></mrow><annotation encoding="application/x-tex">y,z</annotation></semantics></math> (Ours)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">87.4</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r">TRM multi-scale <math alttext="z" class="ltx_Math" display="inline" id="S4.T2.m2" intent=":literal"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_r"><math alttext="n+1=7" class="ltx_Math" display="inline" id="S4.T2.m3" intent=":literal"><semantics><mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow><mo>=</mo><mn>7</mn></mrow><annotation encoding="application/x-tex">n+1=7</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r">77.6</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r">TRM single <math alttext="z" class="ltx_Math" display="inline" id="S4.T2.m4" intent=":literal"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r">1</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r">71.9</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Single network</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p">HRM uses two networks, one applied frequently as a <em class="ltx_emph ltx_font_italic">low-level</em> module <math alttext="f_{H}" class="ltx_Math" display="inline" id="S4.SS3.p1.m1" intent=":literal"><semantics><msub><mi>f</mi><mi>H</mi></msub><annotation encoding="application/x-tex">f_{H}</annotation></semantics></math> and one applied rarely as an <em class="ltx_emph ltx_font_italic">high-level</em> module (<math alttext="f_{H}" class="ltx_Math" display="inline" id="S4.SS3.p1.m2" intent=":literal"><semantics><msub><mi>f</mi><mi>H</mi></msub><annotation encoding="application/x-tex">f_{H}</annotation></semantics></math>). This requires twice the number of parameters compared to regular supervised learning with a single network.</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p">As mentioned previously, while <math alttext="f_{L}" class="ltx_Math" display="inline" id="S4.SS3.p2.m1" intent=":literal"><semantics><msub><mi>f</mi><mi>L</mi></msub><annotation encoding="application/x-tex">f_{L}</annotation></semantics></math> iterates on the latent reasoning feature <math alttext="z" class="ltx_Math" display="inline" id="S4.SS3.p2.m2" intent=":literal"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math> (<math alttext="z_{L}" class="ltx_Math" display="inline" id="S4.SS3.p2.m3" intent=":literal"><semantics><msub><mi>z</mi><mi>L</mi></msub><annotation encoding="application/x-tex">z_{L}</annotation></semantics></math> in HRM), the goal of <math alttext="f_{H}" class="ltx_Math" display="inline" id="S4.SS3.p2.m4" intent=":literal"><semantics><msub><mi>f</mi><mi>H</mi></msub><annotation encoding="application/x-tex">f_{H}</annotation></semantics></math> is to update the solution <math alttext="y" class="ltx_Math" display="inline" id="S4.SS3.p2.m5" intent=":literal"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math> (<math alttext="z_{H}" class="ltx_Math" display="inline" id="S4.SS3.p2.m6" intent=":literal"><semantics><msub><mi>z</mi><mi>H</mi></msub><annotation encoding="application/x-tex">z_{H}</annotation></semantics></math> in HRM) given the latent reasoning and current solution. Importantly, since <math alttext="z\leftarrow f_{L}(x+y+z)" class="ltx_Math" display="inline" id="S4.SS3.p2.m7" intent=":literal"><semantics><mrow><mi>z</mi><mo stretchy="false">←</mo><mrow><msub><mi>f</mi><mi>L</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>x</mi><mo>+</mo><mi>y</mi><mo>+</mo><mi>z</mi></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">z\leftarrow f_{L}(x+y+z)</annotation></semantics></math> contains <math alttext="x" class="ltx_Math" display="inline" id="S4.SS3.p2.m8" intent=":literal"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math> but <math alttext="y\leftarrow f_{H}(y+z)" class="ltx_Math" display="inline" id="S4.SS3.p2.m9" intent=":literal"><semantics><mrow><mi>y</mi><mo stretchy="false">←</mo><mrow><msub><mi>f</mi><mi>H</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>y</mi><mo>+</mo><mi>z</mi></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">y\leftarrow f_{H}(y+z)</annotation></semantics></math> does not contains <math alttext="x" class="ltx_Math" display="inline" id="S4.SS3.p2.m10" intent=":literal"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math>, the task to achieve (iterating on <math alttext="z" class="ltx_Math" display="inline" id="S4.SS3.p2.m11" intent=":literal"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math> versus using <math alttext="z" class="ltx_Math" display="inline" id="S4.SS3.p2.m12" intent=":literal"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math> to update <math alttext="y" class="ltx_Math" display="inline" id="S4.SS3.p2.m13" intent=":literal"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>) is directly specified by the inclusion or lack of <math alttext="x" class="ltx_Math" display="inline" id="S4.SS3.p2.m14" intent=":literal"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math> in the inputs. Thus, we considered the possibility that both networks could be replaced by a single network doing both tasks. In doing so, we obtain better generalization on Sudoku-Extreme (improving TRM from 82.4% to 87.4%; see Table 1) while reducing the number of parameters by half. It turns out that a single network is enough.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Less is more</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p">We attempted to increase capacity by increasing the number of layers in order to scale the model. Surprisingly, we found that adding layers decreased generalization due to overfitting. In doing the opposite, decreasing the number of layers while scaling the number of recursions (<math alttext="n" class="ltx_Math" display="inline" id="S4.SS4.p1.m1" intent=":literal"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>) proportionally (to keep the amount of compute and emulated depth approximately the same), we found that using 2 layers (instead of 4 layers) maximized generalization. In doing so, we obtain better generalization on Sudoku-Extreme (improving TRM from 79.5% to 87.4%; see Table 1) while reducing the number of parameters by half (again).</p>
</div>
<div class="ltx_para" id="S4.SS4.p2">
<p class="ltx_p">It is quite surprising that smaller networks are better, but 2 layers seems to be the optimal choice. <cite class="ltx_cite ltx_citemacro_citet">Bai &amp; Melas-Kyriazi (<a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib4" title="">2024</a>)</cite> also observed optimal performance for 2-layers in the context of deep equilibrium diffusion models; however, they had similar performance to the bigger networks, while we instead observe better performance with 2 layers. This may appear unusual, as with modern neural networks, generalization tends to directly correlate with model sizes. However, when data is too scarce and model size is large, there can be an overfitting penalty <cite class="ltx_cite ltx_citemacro_citep">(Kaplan et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib15" title="">2020</a>)</cite>. This is likely an indication that there is too little data. Thus, using tiny networks with deep recursion and deep supervision appears to allow us to bypass a lot of the overfitting.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>attention-free architecture for tasks with small fixed context length</h3>
<div class="ltx_para" id="S4.SS5.p1">
<p class="ltx_p">Self-attention is particularly good for long-context lengths when <math alttext="L\gg D" class="ltx_Math" display="inline" id="S4.SS5.p1.m1" intent=":literal"><semantics><mrow><mi>L</mi><mo>≫</mo><mi>D</mi></mrow><annotation encoding="application/x-tex">L\gg D</annotation></semantics></math> since it only requires a matrix of <math alttext="[D,3D]" class="ltx_Math" display="inline" id="S4.SS5.p1.m2" intent=":literal"><semantics><mrow><mo stretchy="false">[</mo><mi>D</mi><mo>,</mo><mrow><mn>3</mn><mo lspace="0em" rspace="0em">​</mo><mi>D</mi></mrow><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[D,3D]</annotation></semantics></math> parameters, even though it can account for the whole sequence. However, when focusing on tasks where <math alttext="L\leq D" class="ltx_Math" display="inline" id="S4.SS5.p1.m3" intent=":literal"><semantics><mrow><mi>L</mi><mo>≤</mo><mi>D</mi></mrow><annotation encoding="application/x-tex">L\leq D</annotation></semantics></math>, a linear layer is cheap, requiring only a matrix of <math alttext="[L,L]" class="ltx_Math" display="inline" id="S4.SS5.p1.m4" intent=":literal"><semantics><mrow><mo stretchy="false">[</mo><mi>L</mi><mo>,</mo><mi>L</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[L,L]</annotation></semantics></math> parameters. Taking inspiration from the MLP-Mixer <cite class="ltx_cite ltx_citemacro_citep">(Tolstikhin et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib32" title="">2021</a>)</cite>, we can replace the self-attention layer with a multilayer perceptron (MLP) applied on the sequence length. Using an MLP instead of self-attention, we obtain better generalization on Sudoku-Extreme (improving from 74.7% to 87.4%; see Table <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S4.T1" title="Table 1 ‣ 4 Tiny Recursion Models ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_tag">1</span></a>). This worked well on Sudoku 9x9 grids, given the small and fixed context length; however, we found this architecture to be suboptimal for tasks with large context length, such as Maze-Hard and ARC-AGI (both using 30x30 grids). We show results with and without self-attention for all experiments.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.6 </span>No additional forward pass needed with ACT</h3>
<div class="ltx_para" id="S4.SS6.p1">
<p class="ltx_p">As previously mentioned, the implementation of ACT in HRM through Q-learning requires two forward passes, which slows down training. We propose a simple solution, which is to get rid of the continue loss (from the Q-learning) and only learn a halting probability through a Binary-Cross-Entropy loss of having reached the correct solution. By removing the continue loss, we remove the need for the expensive second forward pass, while still being able to determine when to halt with relatively good accuracy. We found no significant difference in generalization from this change (going from 86.1% to 87.4%; see Table <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S4.T1" title="Table 1 ‣ 4 Tiny Recursion Models ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_tag">1</span></a>).</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS7">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.7 </span>Exponential Moving Average (EMA)</h3>
<div class="ltx_para" id="S4.SS7.p1">
<p class="ltx_p">On small data (such as Sudoku-Extreme and Maze-Hard), HRM tends to overfit quickly and then diverge. To reduce this problem and improves stability, we integrate Exponential Moving Average (EMA) of the weights, a common technique in GANs and diffusion models to improve stability <cite class="ltx_cite ltx_citemacro_citep">(Brock et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib5" title="">2018</a>; Song &amp; Ermon, <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib30" title="">2020</a>)</cite>. We find that it prevents sharp collapse and leads to higher generalization (going from 79.9% to 87.4%; see Table <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S4.T1" title="Table 1 ‣ 4 Tiny Recursion Models ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_tag">1</span></a>).</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS8">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.8 </span>Optimal the number of recursions</h3>
<div class="ltx_para" id="S4.SS8.p1">
<p class="ltx_p">We experimented with different number of recursions by varying <math alttext="T" class="ltx_Math" display="inline" id="S4.SS8.p1.m1" intent=":literal"><semantics><mi>T</mi><annotation encoding="application/x-tex">T</annotation></semantics></math> and <math alttext="n" class="ltx_Math" display="inline" id="S4.SS8.p1.m2" intent=":literal"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math> and found that <math alttext="T=3,n=3" class="ltx_Math" display="inline" id="S4.SS8.p1.m3" intent=":literal"><semantics><mrow><mrow><mi>T</mi><mo>=</mo><mn>3</mn></mrow><mo>,</mo><mrow><mi>n</mi><mo>=</mo><mn>3</mn></mrow></mrow><annotation encoding="application/x-tex">T=3,n=3</annotation></semantics></math> (equivalent to 48 recursions) in HRM and <math alttext="T=3,n=6" class="ltx_Math" display="inline" id="S4.SS8.p1.m4" intent=":literal"><semantics><mrow><mrow><mi>T</mi><mo>=</mo><mn>3</mn></mrow><mo>,</mo><mrow><mi>n</mi><mo>=</mo><mn>6</mn></mrow></mrow><annotation encoding="application/x-tex">T=3,n=6</annotation></semantics></math> in TRM (equivalent to 42 recursions) to lead to optimal generalization on Sudoku-Extreme. More recursions could be helpful for harder problems (we have not tested it, given our limited resources); however, increasing either <math alttext="T" class="ltx_Math" display="inline" id="S4.SS8.p1.m5" intent=":literal"><semantics><mi>T</mi><annotation encoding="application/x-tex">T</annotation></semantics></math> or <math alttext="n" class="ltx_Math" display="inline" id="S4.SS8.p1.m6" intent=":literal"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math> incurs massive slowdowns. We show results at different <math alttext="n" class="ltx_Math" display="inline" id="S4.SS8.p1.m7" intent=":literal"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math> and <math alttext="T" class="ltx_Math" display="inline" id="S4.SS8.p1.m8" intent=":literal"><semantics><mi>T</mi><annotation encoding="application/x-tex">T</annotation></semantics></math> for HRM and TRM in Table <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S4.T3" title="Table 3 ‣ 4.8 Optimal the number of recursions ‣ 4 Tiny Recursion Models ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_tag">3</span></a>. Note that TRM requires backpropagation through a full recursion process, thus increasing <math alttext="n" class="ltx_Math" display="inline" id="S4.SS8.p1.m9" intent=":literal"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math> too much leads to Out Of Memory (OOM) errors. However, this memory cost is well worth its price in gold.</p>
</div>
<figure class="ltx_table" id="S4.T3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>% Test accuracy on Sudoku-Extreme dataset. HRM versus TRM matched at a similar effective depth per supervision step <math alttext="(T(n+1)n_{layers})" class="ltx_Math" display="inline" id="S4.T3.m2" intent=":literal"><semantics><mrow><mo stretchy="false">(</mo><mrow><mi>T</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy="false">)</mo></mrow><mo lspace="0em" rspace="0em">​</mo><msub><mi>n</mi><mrow><mi>l</mi><mo lspace="0em" rspace="0em">​</mo><mi>a</mi><mo lspace="0em" rspace="0em">​</mo><mi>y</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>r</mi><mo lspace="0em" rspace="0em">​</mo><mi>s</mi></mrow></msub></mrow><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(T(n+1)n_{layers})</annotation></semantics></math></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_t"></th>
<th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_rr ltx_border_t"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_rr ltx_border_t" colspan="2">HRM</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" colspan="2">TRM</th>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l"></th>
<th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_rr"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_rr" colspan="2">
<math alttext="n=k" class="ltx_Math" display="inline" id="S4.T3.m3" intent=":literal"><semantics><mrow><mi>n</mi><mo>=</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">n=k</annotation></semantics></math>, 4 layers</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r" colspan="2">
<math alttext="n=2k" class="ltx_Math" display="inline" id="S4.T3.m4" intent=":literal"><semantics><mrow><mi>n</mi><mo>=</mo><mrow><mn>2</mn><mo lspace="0em" rspace="0em">​</mo><mi>k</mi></mrow></mrow><annotation encoding="application/x-tex">n=2k</annotation></semantics></math>, 2 layers</th>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_t"><math alttext="k" class="ltx_Math" display="inline" id="S4.T3.m5" intent=":literal"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_rr ltx_border_t"><math alttext="T" class="ltx_Math" display="inline" id="S4.T3.m6" intent=":literal"><semantics><mi>T</mi><annotation encoding="application/x-tex">T</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Depth</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_t">Acc (%)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Depth</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Acc (%)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_t">1</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t">1</th>
<td class="ltx_td ltx_align_center ltx_border_t">9</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">46.4</td>
<td class="ltx_td ltx_align_center ltx_border_t">7</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.2</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l">2</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr">2</th>
<td class="ltx_td ltx_align_center">24</td>
<td class="ltx_td ltx_align_center ltx_border_rr">55.0</td>
<td class="ltx_td ltx_align_center">20</td>
<td class="ltx_td ltx_align_center ltx_border_r">81.9</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l">3</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr">3</th>
<td class="ltx_td ltx_align_center">48</td>
<td class="ltx_td ltx_align_center ltx_border_rr">61.6</td>
<td class="ltx_td ltx_align_center">42</td>
<td class="ltx_td ltx_align_center ltx_border_r">87.4</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l">4</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr">4</th>
<td class="ltx_td ltx_align_center">80</td>
<td class="ltx_td ltx_align_center ltx_border_rr">59.5</td>
<td class="ltx_td ltx_align_center">72</td>
<td class="ltx_td ltx_align_center ltx_border_r">84.2</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l">6</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr">3</th>
<td class="ltx_td ltx_align_center">84</td>
<td class="ltx_td ltx_align_center ltx_border_rr">62.3</td>
<td class="ltx_td ltx_align_center">78</td>
<td class="ltx_td ltx_align_center ltx_border_r">OOM</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l">3</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr">6</th>
<td class="ltx_td ltx_align_center">96</td>
<td class="ltx_td ltx_align_center ltx_border_rr">58.8</td>
<td class="ltx_td ltx_align_center">84</td>
<td class="ltx_td ltx_align_center ltx_border_r">85.8</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l">6</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_rr">6</th>
<td class="ltx_td ltx_align_center ltx_border_b">168</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_rr">57.5</td>
<td class="ltx_td ltx_align_center ltx_border_b">156</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r">OOM</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S4.SS8.p2">
<p class="ltx_p">In the following section, we show our main results on multiple datasets comparing HRM, TRM, and LLMs.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Results</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p">Following <cite class="ltx_cite ltx_citemacro_citet">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib34" title="">2025</a>)</cite>, we test our approach on the following datasets: Sudoku-Extreme <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib34" title="">2025</a>)</cite>, Maze-Hard <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib34" title="">2025</a>)</cite>, ARC-AGI-1 <cite class="ltx_cite ltx_citemacro_citep">(Chollet, <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib6" title="">2019</a>)</cite> and, ARC-AGI-2 <cite class="ltx_cite ltx_citemacro_citep">(Chollet et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib7" title="">2025</a>)</cite>. Results are presented in Tables <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S5.T4" title="Table 4 ‣ 5 Results ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_tag">4</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S5.T5" title="Table 5 ‣ 5 Results ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_tag">5</span></a>. Hyperparameters are detailed in Section <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#Ax1" title="Hyper-parameters and setup ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_title">Hyper-parameters and setup</span></a>. Datasets are discussed below.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p">Sudoku-Extreme consists of extremely difficult Sudoku puzzles <cite class="ltx_cite ltx_citemacro_citep">(Dillion, <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib9" title="">2025</a>; Palm et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib23" title="">2018</a>; Park, <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib24" title="">2018</a>)</cite> (9x9 grid), for which only 1K training samples are used to test small-sample learning. Testing is done on 423K samples. Maze-Hard consists of 30x30 mazes generated by the procedure by <cite class="ltx_cite ltx_citemacro_citet">Lehnert et al. (<a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib19" title="">2024</a>)</cite> whose shortest path is of length above 110; both the training set and test set include 1000 mazes.</p>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p">ARC-AGI-1 and ARC-AGI-2 are geometric puzzles involving monetary prizes. Each puzzle is designed to be easy for a human, yet hard for current AI models. Each puzzle task consists of 2-3 input–output demonstration pairs and 1-2 test inputs to be solved. The final score is computed as the accuracy over all test inputs from two attempts to produce the correct output grid. The maximum grid size is 30x30. ARC-AGI-1 contains 800 tasks, while ARC-AGI-2 contains 1120 tasks. We also augment our data with the 160 tasks from the closely related ConceptARC dataset <cite class="ltx_cite ltx_citemacro_citep">(Moskvichev et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib22" title="">2023</a>)</cite>. We provide results on the public evaluation set for both ARC-AGI-1 and ARC-AGI-2.</p>
</div>
<div class="ltx_para" id="S5.p4">
<p class="ltx_p">While these datasets are small, heavy data-augmentation is used in order to improve generalization. Sudoku-Extreme uses 1000 shuffling (done without breaking the Sudoku rules) augmentations per data example. Maze-Hard uses 8 dihedral transformations per data example. ARC-AGI uses 1000 data augmentations (color permutation, dihedral-group, and translations transformations) per data example. The dihedral-group transformations consist of random 90-degree rotations, horizontal/vertical flips, and reflections.</p>
</div>
<div class="ltx_para" id="S5.p5">
<p class="ltx_p">From the results, we see that TRM without self-attention obtains the best generalization on Sudoku-Extreme (87.4% test accuracy). Meanwhile, TRM with self-attention generalizes better on the other tasks (probably due to inductive biases and the overcapacity of the MLP on large 30x30 grids). TRM with self-attention obtains 85.3% accuracy on Maze-Hard, 44.6% accuracy on ARC-AGI-1, and 7.8% accuracy on ARC-AGI-2 with 7M parameters. This is significantly higher than the 74.5%, 40.3%, and 5.0% obtained by HRM using 4 times the number of parameters (27M).</p>
</div>
<figure class="ltx_table" id="S5.T4">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>% Test accuracy on Puzzle Benchmarks (Sudoku-Extreme and Maze-Hard)</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">Method</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"># Params</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">Sudoku</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">Maze</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" colspan="4" style="padding-left:4.0pt;padding-right:4.0pt;">Chain-of-thought, pretrained</th>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">Deepseek R1</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">671B</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">0.0</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">Claude 3.7 8K</th>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">?</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">0.0</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">O3-mini-high</th>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">?</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">0.0</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" colspan="4" style="padding-left:4.0pt;padding-right:4.0pt;">Direct prediction, small-sample training</th>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">Direct pred</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">27M</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">0.0</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">HRM</th>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">27M</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">55.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">74.5</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">TRM-Att (Ours)</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">7M</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">74.7</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" style="--ltx-bg-color:#D9FFD9;">85.3</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">TRM-MLP (Ours)</th>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">5M/19M<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>5M on Sudoku and 19M on Maze</span></span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" style="--ltx-bg-color:#D9FFD9;">87.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">0.0</td>
</tr>
</tbody>
</table>
</figure>
<figure class="ltx_table" id="S5.T5">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span>% Test accuracy on ARC-AGI Benchmarks (2 tries)</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">Method</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"># Params</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">ARC-1</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">ARC-2</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" colspan="4" style="padding-left:4.0pt;padding-right:4.0pt;">Chain-of-thought, pretrained</th>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">Deepseek R1</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">671B</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">15.8</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">1.3</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">Claude 3.7 16K</th>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">?</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">28.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">0.7</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">o3-mini-high</th>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">?</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">34.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">3.0</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">Gemini 2.5 Pro 32K</th>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">?</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">37.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">4.9</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">Grok-4-thinking</th>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">1.7T</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">66.7</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">16.0</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">Bespoke (Grok-4)</th>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">1.7T</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" style="--ltx-bg-color:#D9FFD9;">79.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" style="--ltx-bg-color:#D9FFD9;">29.4</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" colspan="4" style="padding-left:4.0pt;padding-right:4.0pt;">Direct prediction, small-sample training</th>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">Direct pred</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">27M</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">21.0</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">0.0</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">HRM</th>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">27M</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">40.3</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">5.0</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">TRM-Att (Ours)</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">7M</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" style="--ltx-bg-color:#D9FFD9;">44.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" style="--ltx-bg-color:#D9FFD9;">7.8</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">TRM-MLP (Ours)</th>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">19M</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">29.6</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">2.4</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p">We propose Tiny Recursion Models (TRM), a simple recursive reasoning approach that achieves strong generalization on hard tasks using a single tiny network recursing on its latent reasoning feature and progressively improving its final answer. Contrary to the Hierarchical Reasoning Model (HRM), TRM requires no fixed-point theorem, no complex biological justifications, and no hierarchy. It significantly reduces the number of parameters by halving the number of layers and replacing the two networks with a single tiny network. It also simplifies the halting process, removing the need for the extra forward pass. Overall, TRM is much simpler than HRM, while achieving better generalization.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p">While our approach led to better generalization on 4 benchmarks, every choice made is not guaranteed to be optimal on every dataset. For example, we found that replacing the self-attention with an MLP worked extremely well on Sudoku-Extreme (improving test accuracy by 10%), but poorly on other datasets. Different problem settings may require different architectures or number of parameters. Scaling laws are needed to parametrize these networks optimally. Although we simplified and improved on deep recursion, the question of why recursion helps so much compared to using a larger and deeper network remains to be explained; we suspect it has to do with overfitting, but we have no theory to back this explaination. Not all our ideas made the cut; we briefly discuss some of the failed ideas that we tried but did not work in Section <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#Ax2" title="Ideas that failed ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_title">Ideas that failed</span></a>. Currently, recursive reasoning models such as HRM and TRM are supervised learning methods rather than generative models. This means that given an input question, they can only provide a single deterministic answer. In many settings, multiple answers exist for a question. Thus, it would be interesting to extend TRM to generative tasks.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p">Thank you Emy Gervais for your invaluable support and extra push. This research was enabled in part by computing resources, software, and technical assistance provided by Mila and the Digital Research Alliance of Canada.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">ARC Prize Foundation (2025a)</span>
<span class="ltx_bibblock">
ARC Prize Foundation.

</span>
<span class="ltx_bibblock">The Hidden Drivers of HRM’s Performance on ARC-AGI.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arcprize.org/blog/hrm-analysis" title="">https://arcprize.org/blog/hrm-analysis</a>, 2025a.

</span>
<span class="ltx_bibblock">[Online; accessed 2025-09-15].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">ARC Prize Foundation (2025b)</span>
<span class="ltx_bibblock">
ARC Prize Foundation.

</span>
<span class="ltx_bibblock">ARC-AGI Leaderboard.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arcprize.org/leaderboard" title="">https://arcprize.org/leaderboard</a>, 2025b.

</span>
<span class="ltx_bibblock">[Online; accessed 2025-09-24].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai et al. (2019)</span>
<span class="ltx_bibblock">
Bai, S., Kolter, J. Z., and Koltun, V.

</span>
<span class="ltx_bibblock">Deep equilibrium models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 32, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai &amp; Melas-Kyriazi (2024)</span>
<span class="ltx_bibblock">
Bai, X. and Melas-Kyriazi, L.

</span>
<span class="ltx_bibblock">Fixed point diffusion models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.  9430–9440, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brock et al. (2018)</span>
<span class="ltx_bibblock">
Brock, A., Donahue, J., and Simonyan, K.

</span>
<span class="ltx_bibblock">Large scale gan training for high fidelity natural image synthesis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1809.11096</em>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chollet (2019)</span>
<span class="ltx_bibblock">
Chollet, F.

</span>
<span class="ltx_bibblock">On the measure of intelligence.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1911.01547</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chollet et al. (2025)</span>
<span class="ltx_bibblock">
Chollet, F., Knoop, M., Kamradt, G., Landers, B., and Pinkard, H.

</span>
<span class="ltx_bibblock">Arc-agi-2: A new challenge for frontier ai reasoning systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2505.11831</em>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chowdhery et al. (2023)</span>
<span class="ltx_bibblock">
Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., et al.

</span>
<span class="ltx_bibblock">Palm: Scaling language modeling with pathways.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Journal of Machine Learning Research</em>, 24(240):1–113, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dillion (2025)</span>
<span class="ltx_bibblock">
Dillion, T.

</span>
<span class="ltx_bibblock">Tdoku: A fast sudoku solver and generator.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://t-dillon.github.io/tdoku/" title="">https://t-dillon.github.io/tdoku/</a>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Elman (1990)</span>
<span class="ltx_bibblock">
Elman, J. L.

</span>
<span class="ltx_bibblock">Finding structure in time.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Cognitive science</em>, 14(2):179–211, 1990.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fedus et al. (2022)</span>
<span class="ltx_bibblock">
Fedus, W., Zoph, B., and Shazeer, N.

</span>
<span class="ltx_bibblock">Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Journal of Machine Learning Research</em>, 23(120):1–39, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geng &amp; Kolter (2023)</span>
<span class="ltx_bibblock">
Geng, Z. and Kolter, J. Z.

</span>
<span class="ltx_bibblock">Torchdeq: A library for deep equilibrium models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.18605</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendrycks &amp; Gimpel (2016)</span>
<span class="ltx_bibblock">
Hendrycks, D. and Gimpel, K.

</span>
<span class="ltx_bibblock">Gaussian error linear units (gelus).

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1606.08415</em>, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jang et al. (2023)</span>
<span class="ltx_bibblock">
Jang, Y., Kim, D., and Ahn, S.

</span>
<span class="ltx_bibblock">Hierarchical graph generation with k2-trees.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic">ICML 2023 Workshop on Structured Probabilistic Inference Generative Modeling</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kaplan et al. (2020)</span>
<span class="ltx_bibblock">
Kaplan, J., McCandlish, S., Henighan, T., Brown, T. B., Chess, B., Child, R., Gray, S., Radford, A., Wu, J., and Amodei, D.

</span>
<span class="ltx_bibblock">Scaling laws for neural language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2001.08361</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kingma &amp; Ba (2014)</span>
<span class="ltx_bibblock">
Kingma, D. P. and Ba, J.

</span>
<span class="ltx_bibblock">Adam: A method for stochastic optimization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1412.6980</em>, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krantz &amp; Parks (2002)</span>
<span class="ltx_bibblock">
Krantz, S. G. and Parks, H. R.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">The implicit function theorem: history, theory, and applications</em>.

</span>
<span class="ltx_bibblock">Springer Science &amp; Business Media, 2002.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">LeCun (1985)</span>
<span class="ltx_bibblock">
LeCun, Y.

</span>
<span class="ltx_bibblock">Une procedure d’apprentissage ponr reseau a seuil asymetrique.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Proceedings of cognitiva 85</em>, pp.  599–604, 1985.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lehnert et al. (2024)</span>
<span class="ltx_bibblock">
Lehnert, L., Sukhbaatar, S., Su, D., Zheng, Q., Mcvay, P., Rabbat, M., and Tian, Y.

</span>
<span class="ltx_bibblock">Beyond a*: Better planning with transformers via search dynamics bootstrapping.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2402.14083</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lillicrap &amp; Santoro (2019)</span>
<span class="ltx_bibblock">
Lillicrap, T. P. and Santoro, A.

</span>
<span class="ltx_bibblock">Backpropagation through time and the brain.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Current opinion in neurobiology</em>, 55:82–89, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Loshchilov &amp; Hutter (2017)</span>
<span class="ltx_bibblock">
Loshchilov, I. and Hutter, F.

</span>
<span class="ltx_bibblock">Decoupled weight decay regularization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1711.05101</em>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Moskvichev et al. (2023)</span>
<span class="ltx_bibblock">
Moskvichev, A., Odouard, V. V., and Mitchell, M.

</span>
<span class="ltx_bibblock">The conceptarc benchmark: Evaluating understanding and generalization in the arc domain.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.07141</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Palm et al. (2018)</span>
<span class="ltx_bibblock">
Palm, R., Paquet, U., and Winther, O.

</span>
<span class="ltx_bibblock">Recurrent relational networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 31, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park (2018)</span>
<span class="ltx_bibblock">
Park, K.

</span>
<span class="ltx_bibblock">Can convolutional neural networks crack sudoku puzzles?

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/Kyubyong/sudoku" title="">https://github.com/Kyubyong/sudoku</a>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Prieto et al. (2025)</span>
<span class="ltx_bibblock">
Prieto, L., Barsbey, M., Mediano, P. A., and Birdal, T.

</span>
<span class="ltx_bibblock">Grokking at the edge of numerical stability.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2501.04697</em>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rumelhart et al. (1985)</span>
<span class="ltx_bibblock">
Rumelhart, D. E., Hinton, G. E., and Williams, R. J.

</span>
<span class="ltx_bibblock">Learning internal representations by error propagation.

</span>
<span class="ltx_bibblock">Technical report, 1985.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shazeer (2020)</span>
<span class="ltx_bibblock">
Shazeer, N.

</span>
<span class="ltx_bibblock">Glu variants improve transformer.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2002.05202</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shazeer et al. (2017)</span>
<span class="ltx_bibblock">
Shazeer, N., Mirhoseini, A., Maziarz, K., Davis, A., Le, Q., Hinton, G., and Dean, J.

</span>
<span class="ltx_bibblock">Outrageously large neural networks: The sparsely-gated mixture-of-experts layer.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1701.06538</em>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Snell et al. (2024)</span>
<span class="ltx_bibblock">
Snell, C., Lee, J., Xu, K., and Kumar, A.

</span>
<span class="ltx_bibblock">Scaling llm test-time compute optimally can be more effective than scaling model parameters.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2408.03314</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Song &amp; Ermon (2020)</span>
<span class="ltx_bibblock">
Song, Y. and Ermon, S.

</span>
<span class="ltx_bibblock">Improved techniques for training score-based generative models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 33:12438–12448, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Su et al. (2024)</span>
<span class="ltx_bibblock">
Su, J., Ahmed, M., Lu, Y., Pan, S., Bo, W., and Liu, Y.

</span>
<span class="ltx_bibblock">Roformer: Enhanced transformer with rotary position embedding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Neurocomputing</em>, 568:127063, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tolstikhin et al. (2021)</span>
<span class="ltx_bibblock">
Tolstikhin, I. O., Houlsby, N., Kolesnikov, A., Beyer, L., Zhai, X., Unterthiner, T., Yung, J., Steiner, A., Keysers, D., Uszkoreit, J., et al.

</span>
<span class="ltx_bibblock">Mlp-mixer: An all-mlp architecture for vision.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 34:24261–24272, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et al. (2017)</span>
<span class="ltx_bibblock">
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., and Polosukhin, I.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 30, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2025)</span>
<span class="ltx_bibblock">
Wang, G., Li, J., Sun, Y., Chen, X., Liu, C., Wu, Y., Lu, M., Song, S., and Yadkori, Y. A.

</span>
<span class="ltx_bibblock">Hierarchical reasoning model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2506.21734</em>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2022)</span>
<span class="ltx_bibblock">
Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q. V., Zhou, D., et al.

</span>
<span class="ltx_bibblock">Chain-of-thought prompting elicits reasoning in large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 35:24824–24837, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Werbos (1974)</span>
<span class="ltx_bibblock">
Werbos, P.

</span>
<span class="ltx_bibblock">Beyond regression: New tools for prediction and analysis in the behavioral sciences.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">PhD thesis, Committee on Applied Mathematics, Harvard University, Cambridge, MA</em>, 1974.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Werbos (1988)</span>
<span class="ltx_bibblock">
Werbos, P. J.

</span>
<span class="ltx_bibblock">Generalization of backpropagation with application to a recurrent gas market model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Neural networks</em>, 1(4):339–356, 1988.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang &amp; Sennrich (2019)</span>
<span class="ltx_bibblock">
Zhang, B. and Sennrich, R.

</span>
<span class="ltx_bibblock">Root mean square layer normalization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 32, 2019.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="Ax1">
<h2 class="ltx_title ltx_title_appendix">Hyper-parameters and setup</h2>
<div class="ltx_para" id="Ax1.p1">
<p class="ltx_p">All models are trained with the AdamW optimizer<cite class="ltx_cite ltx_citemacro_citep">(Loshchilov &amp; Hutter, <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib21" title="">2017</a>; Kingma &amp; Ba, <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib16" title="">2014</a>)</cite> with <math alttext="\beta_{1}=0.9" class="ltx_Math" display="inline" id="Ax1.p1.m1" intent=":literal"><semantics><mrow><msub><mi>β</mi><mn>1</mn></msub><mo>=</mo><mn>0.9</mn></mrow><annotation encoding="application/x-tex">\beta_{1}=0.9</annotation></semantics></math>, <math alttext="\beta_{2}=0.95" class="ltx_Math" display="inline" id="Ax1.p1.m2" intent=":literal"><semantics><mrow><msub><mi>β</mi><mn>2</mn></msub><mo>=</mo><mn>0.95</mn></mrow><annotation encoding="application/x-tex">\beta_{2}=0.95</annotation></semantics></math>, small learning rate warm-up (2K iterations), batch-size 768, hidden-size of 512, <math alttext="N_{sup}=16" class="ltx_Math" display="inline" id="Ax1.p1.m3" intent=":literal"><semantics><mrow><msub><mi>N</mi><mrow><mi>s</mi><mo lspace="0em" rspace="0em">​</mo><mi>u</mi><mo lspace="0em" rspace="0em">​</mo><mi>p</mi></mrow></msub><mo>=</mo><mn>16</mn></mrow><annotation encoding="application/x-tex">N_{sup}=16</annotation></semantics></math> max supervision steps, and stable-max loss <cite class="ltx_cite ltx_citemacro_citep">(Prieto et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib25" title="">2025</a>)</cite> for improved stability. TRM uses an Exponential Moving Average (EMA) of 0.999. HRM uses <math alttext="n=2,T=2" class="ltx_Math" display="inline" id="Ax1.p1.m4" intent=":literal"><semantics><mrow><mrow><mi>n</mi><mo>=</mo><mn>2</mn></mrow><mo>,</mo><mrow><mi>T</mi><mo>=</mo><mn>2</mn></mrow></mrow><annotation encoding="application/x-tex">n=2,T=2</annotation></semantics></math> with two 4-layers networks, while we use <math alttext="n=6,T=3" class="ltx_Math" display="inline" id="Ax1.p1.m5" intent=":literal"><semantics><mrow><mrow><mi>n</mi><mo>=</mo><mn>6</mn></mrow><mo>,</mo><mrow><mi>T</mi><mo>=</mo><mn>3</mn></mrow></mrow><annotation encoding="application/x-tex">n=6,T=3</annotation></semantics></math> with one 2-layer network.</p>
</div>
<div class="ltx_para" id="Ax1.p2">
<p class="ltx_p">For Sudoku-Extreme and Maze-Hard, we train for 60k epochs with learning rate 1e-4 and weight decay 1.0. For ARC-AGI, we train for 100K epochs with learning rate 1e-4 (with 1e-2 learning rate for the embeddings) and weight decay 0.1. The numbers for Deepseek R1, Claude 3.7 8K, O3-mini-high, Direct prediction, and HRM from the Table <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S5.T4" title="Table 4 ‣ 5 Results ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_tag">4</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#S5.T5" title="Table 5 ‣ 5 Results ‣ Less is More: Recursive Reasoning with Tiny Networks"><span class="ltx_text ltx_ref_tag">5</span></a> are taken from <cite class="ltx_cite ltx_citemacro_citet">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib34" title="">2025</a>)</cite>. Both HRM and TRM add an embedding of shape <math alttext="[0,1,D]" class="ltx_Math" display="inline" id="Ax1.p2.m1" intent=":literal"><semantics><mrow><mo stretchy="false">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo>,</mo><mi>D</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[0,1,D]</annotation></semantics></math> on Sudoku-Extreme and Maze-Hard to the input. For ARC-AGI, each puzzle (containing 2-3 training examples and 1-2 test examples) at each data-augmentation is given a specific embedding of shape <math alttext="[0,1,D]" class="ltx_Math" display="inline" id="Ax1.p2.m2" intent=":literal"><semantics><mrow><mo stretchy="false">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo>,</mo><mi>D</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[0,1,D]</annotation></semantics></math> and, at test-time, the most common answer out of the 1000 data augmentations is given as answer.</p>
</div>
<div class="ltx_para" id="Ax1.p3">
<p class="ltx_p">Experiments on Sudoku-Extreme were ran with 1 L40S with 40Gb of RAM for generally less than 36 hours. Experiments on Maze-Hard were ran with 4 L40S with 40Gb of RAM for less than 24 hours. Experiments on ARC-AGI were ran for around 3 days with 4 H100 with 80Gb of RAM.</p>
</div>
</section>
<section class="ltx_appendix" id="Ax2">
<h2 class="ltx_title ltx_title_appendix">Ideas that failed</h2>
<div class="ltx_para" id="Ax2.p1">
<p class="ltx_p">In this section, we quickly mention a few ideas that did not work to prevent others from making the same mistake.</p>
</div>
<div class="ltx_para" id="Ax2.p2">
<p class="ltx_p">We tried replacing the SwiGLU MLPs by SwiGLU Mixture-of-Experts (MoEs) <cite class="ltx_cite ltx_citemacro_citep">(Shazeer et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib28" title="">2017</a>; Fedus et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib11" title="">2022</a>)</cite>, but we found generalization to decrease massively. MoEs clearly add too much unnecessary capacity, just like increasing the number of layers does.</p>
</div>
<div class="ltx_para" id="Ax2.p3">
<p class="ltx_p">Instead of back-propagating through the whole <math alttext="n+1" class="ltx_Math" display="inline" id="Ax2.p3.m1" intent=":literal"><semantics><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">n+1</annotation></semantics></math> recursions, we tried a compromise between HRM 1-step gradient approximation, which back-propagates through the last 2 recursions. We did so by decoupling <math alttext="n" class="ltx_Math" display="inline" id="Ax2.p3.m2" intent=":literal"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math> from the <em class="ltx_emph ltx_font_italic">number of last recursions</em> <math alttext="k" class="ltx_Math" display="inline" id="Ax2.p3.m3" intent=":literal"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math> that we back-propagate through. For example, while <math alttext="n=6" class="ltx_Math" display="inline" id="Ax2.p3.m4" intent=":literal"><semantics><mrow><mi>n</mi><mo>=</mo><mn>6</mn></mrow><annotation encoding="application/x-tex">n=6</annotation></semantics></math> requires 7 steps with gradients in TRM, we can use gradients for only the <math alttext="k=4" class="ltx_Math" display="inline" id="Ax2.p3.m5" intent=":literal"><semantics><mrow><mi>k</mi><mo>=</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">k=4</annotation></semantics></math> last steps. However, we found that this did not help generalization in any way, and it made the approach more complicated. Back-propagating through the whole <math alttext="n+1" class="ltx_Math" display="inline" id="Ax2.p3.m6" intent=":literal"><semantics><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">n+1</annotation></semantics></math> recursions makes the most sense and works best.</p>
</div>
<div class="ltx_para" id="Ax2.p4">
<p class="ltx_p">We tried removing ACT with the option of stopping when the solution is reached, but we found that generalization dropped significantly. This can probably be attributed to the fact that the model is spending too much time on the same data samples rather than focusing on learning on a wide range of data samples.</p>
</div>
<div class="ltx_para" id="Ax2.p5">
<p class="ltx_p">We tried weight tying the input embedding and output head, but this was too constraining and led to a massive generalization drop.</p>
</div>
<div class="ltx_para" id="Ax2.p6">
<p class="ltx_p">We tried using TorchDEQ <cite class="ltx_cite ltx_citemacro_citep">(Geng &amp; Kolter, <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib12" title="">2023</a>)</cite> to replace the recursion steps by fixed-point iteration as done by Deep Equilibrium Models <cite class="ltx_cite ltx_citemacro_citep">(Bai et al., <a class="ltx_ref" href="https://arxiv.org/html/2510.04871v1#bib.bib3" title="">2019</a>)</cite>. This would provide a better justification for the 1-step gradient approximation. However, this slowed down training due to the fixed-point iteration and led to worse generalization. This highlights the fact that converging to a fixed-point is not essential.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_appendix" id="Ax3">
<h2 class="ltx_title ltx_title_appendix">Algorithms with different number of latent features</h2>
<figure class="ltx_figure" id="Ax3.F4">
<div class="ltx_listing ltx_lst_language_python ltx_lstlisting ltx_align_center ltx_listing" style="--ltx-bg-color:#FFFFFF;">
<div class="ltx_listing_data"><a download="" href="data:text/plain;base64,CmRlZiBsYXRlbnRfcmVjdXJzaW9uKHgsIHosIG49Nik6CiAgICBmb3IgaSBpbiByYW5nZShuKzEpOiAjIGxhdGVudCByZWN1cnNpb24KICAgICAgICB6ID0gbmV0KHgsIHopCiAgICByZXR1cm4gegoKZGVmIGRlZXBfcmVjdXJzaW9uKHgsIHosIG49NiwgVD0zKToKICAgICMgcmVjdXJzaW5nIFQtMSB0aW1lcyB0byBpbXByb3ZlIHogKG5vIGdyYWRpZW50cyBuZWVkZWQpCiAgICB3aXRoIHRvcmNoLm5vX2dyYWQoKToKICAgICAgICBmb3IgaiBpbiByYW5nZShULTEpOgogICAgICAgICAgICB6ID0gbGF0ZW50X3JlY3Vyc2lvbih4LCB6LCBuKQogICAgIyByZWN1cnNpbmcgb25jZSB0byBpbXByb3ZlIHoKICAgIHogPSBsYXRlbnRfcmVjdXJzaW9uKHgsIHosIG4pCiAgICByZXR1cm4gei5kZXRhY2goKSwgb3V0cHV0X2hlYWQoeSksIFFfaGVhZCh5KQoKIyBEZWVwIFN1cGVydmlzaW9uCmZvciB4X2lucHV0LCB5X3RydWUgaW4gdHJhaW5fZGF0YWxvYWRlcjoKICAgIHogPSB6X2luaXQKICAgIGZvciBzdGVwIGluIHJhbmdlKE5fc3VwZXJ2aXNpb24pOgogICAgICAgIHggPSBpbnB1dF9lbWJlZGRpbmcoeF9pbnB1dCkKICAgICAgICB6LCB5X2hhdCwgcV9oYXQgPSBkZWVwX3JlY3Vyc2lvbih4LCB6KQogICAgICAgIGxvc3MgPSBzb2Z0bWF4X2Nyb3NzX2VudHJvcHkoeV9oYXQsIHlfdHJ1ZSkKICAgICAgICBsb3NzICs9IGJpbmFyeV9jcm9zc19lbnRyb3B5KHFfaGF0LCAoeV9oYXQgPT0geV90cnVlKSkKICAgICAgICB6ID0gei5kZXRhY2goKQogICAgICAgIGxvc3MuYmFja3dhcmQoKQogICAgICAgIG9wdC5zdGVwKCkKICAgICAgICBvcHQuemVyb19ncmFkKCkKICAgICAgICBpZiBxWzBdID4gMDogIyBlYXJseS1zdG9wcGluZwogICAgICAgICAgICBicmVhaw==">⬇</a></div>
<div class="ltx_listingline" id="lstnumberx72">
</div>
<div class="ltx_listingline" id="lstnumberx73">
<span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">def</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">latent_recursion</span>(<span class="ltx_text ltx_lst_identifier">x</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">n</span>=6):
</div>
<div class="ltx_listingline" id="lstnumberx74">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">for</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">i</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">in</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword ltx_lst_keywords2" style="--ltx-fg-color:#0000FF;">range</span>(<span class="ltx_text ltx_lst_identifier">n</span>+1):<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_comment" style="--ltx-fg-color:#808080;">#<span class="ltx_text ltx_lst_space"> </span>latent<span class="ltx_text ltx_lst_space"> </span>recursion</span>
</div>
<div class="ltx_listingline" id="lstnumberx75">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">net</span>(<span class="ltx_text ltx_lst_identifier">x</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>)
</div>
<div class="ltx_listingline" id="lstnumberx76">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">return</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>
</div>
<div class="ltx_listingline" id="lstnumberx77">
</div>
<div class="ltx_listingline" id="lstnumberx78">
<span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">def</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">deep_recursion</span>(<span class="ltx_text ltx_lst_identifier">x</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">n</span>=6,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">T</span>=3):
</div>
<div class="ltx_listingline" id="lstnumberx79">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_comment" style="--ltx-fg-color:#808080;">#<span class="ltx_text ltx_lst_space"> </span>recursing<span class="ltx_text ltx_lst_space"> </span>T-1<span class="ltx_text ltx_lst_space"> </span>times<span class="ltx_text ltx_lst_space"> </span>to<span class="ltx_text ltx_lst_space"> </span>improve<span class="ltx_text ltx_lst_space"> </span>z<span class="ltx_text ltx_lst_space"> </span>(no<span class="ltx_text ltx_lst_space"> </span>gradients<span class="ltx_text ltx_lst_space"> </span>needed)</span>
</div>
<div class="ltx_listingline" id="lstnumberx80">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">with</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">torch</span>.<span class="ltx_text ltx_lst_identifier">no_grad</span>():
</div>
<div class="ltx_listingline" id="lstnumberx81">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">for</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">j</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">in</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword ltx_lst_keywords2" style="--ltx-fg-color:#0000FF;">range</span>(<span class="ltx_text ltx_lst_identifier">T</span>-1):
</div>
<div class="ltx_listingline" id="lstnumberx82">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">latent_recursion</span>(<span class="ltx_text ltx_lst_identifier">x</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">n</span>)
</div>
<div class="ltx_listingline" id="lstnumberx83">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_comment" style="--ltx-fg-color:#808080;">#<span class="ltx_text ltx_lst_space"> </span>recursing<span class="ltx_text ltx_lst_space"> </span>once<span class="ltx_text ltx_lst_space"> </span>to<span class="ltx_text ltx_lst_space"> </span>improve<span class="ltx_text ltx_lst_space"> </span>z</span>
</div>
<div class="ltx_listingline" id="lstnumberx84">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">latent_recursion</span>(<span class="ltx_text ltx_lst_identifier">x</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">n</span>)
</div>
<div class="ltx_listingline" id="lstnumberx85">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">return</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>.<span class="ltx_text ltx_lst_identifier">detach</span>(),<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">output_head</span>(<span class="ltx_text ltx_lst_identifier">y</span>),<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">Q_head</span>(<span class="ltx_text ltx_lst_identifier">y</span>)
</div>
<div class="ltx_listingline" id="lstnumberx86">
</div>
<div class="ltx_listingline" id="lstnumberx87">
<span class="ltx_text ltx_lst_comment" style="--ltx-fg-color:#808080;">#<span class="ltx_text ltx_lst_space"> </span>Deep<span class="ltx_text ltx_lst_space"> </span>Supervision</span>
</div>
<div class="ltx_listingline" id="lstnumberx88">
<span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">for</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">x_input</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y_true</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">in</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">train_dataloader</span>:
</div>
<div class="ltx_listingline" id="lstnumberx89">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z_init</span>
</div>
<div class="ltx_listingline" id="lstnumberx90">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">for</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">step</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">in</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword ltx_lst_keywords2" style="--ltx-fg-color:#0000FF;">range</span>(<span class="ltx_text ltx_lst_identifier">N_supervision</span>):
</div>
<div class="ltx_listingline" id="lstnumberx91">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">x</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">input_embedding</span>(<span class="ltx_text ltx_lst_identifier">x_input</span>)
</div>
<div class="ltx_listingline" id="lstnumberx92">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y_hat</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">q_hat</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">deep_recursion</span>(<span class="ltx_text ltx_lst_identifier">x</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>)
</div>
<div class="ltx_listingline" id="lstnumberx93">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">loss</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">softmax_cross_entropy</span>(<span class="ltx_text ltx_lst_identifier">y_hat</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y_true</span>)
</div>
<div class="ltx_listingline" id="lstnumberx94">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">loss</span><span class="ltx_text ltx_lst_space"> </span>+=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">binary_cross_entropy</span>(<span class="ltx_text ltx_lst_identifier">q_hat</span>,<span class="ltx_text ltx_lst_space"> </span>(<span class="ltx_text ltx_lst_identifier">y_hat</span><span class="ltx_text ltx_lst_space"> </span>==<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y_true</span>))
</div>
<div class="ltx_listingline" id="lstnumberx95">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>.<span class="ltx_text ltx_lst_identifier">detach</span>()
</div>
<div class="ltx_listingline" id="lstnumberx96">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">loss</span>.<span class="ltx_text ltx_lst_identifier">backward</span>()
</div>
<div class="ltx_listingline" id="lstnumberx97">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">opt</span>.<span class="ltx_text ltx_lst_identifier">step</span>()
</div>
<div class="ltx_listingline" id="lstnumberx98">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">opt</span>.<span class="ltx_text ltx_lst_identifier">zero_grad</span>()
</div>
<div class="ltx_listingline" id="lstnumberx99">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">if</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">q</span>[0]<span class="ltx_text ltx_lst_space"> </span>&gt;<span class="ltx_text ltx_lst_space"> </span>0:<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_comment" style="--ltx-fg-color:#808080;">#<span class="ltx_text ltx_lst_space"> </span>early-stopping</span>
</div>
<div class="ltx_listingline" id="lstnumberx100">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">break</span>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Pseudocode of TRM using a single-<math alttext="z" class="ltx_Math" display="inline" id="Ax3.F4.m2" intent=":literal"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math> with deep supervision training in PyTorch.</figcaption>
</figure>
<figure class="ltx_figure" id="Ax3.F5">
<div class="ltx_listing ltx_lst_language_python ltx_lstlisting ltx_align_center ltx_listing" style="--ltx-bg-color:#FFFFFF;">
<div class="ltx_listing_data"><a download="" href="data:text/plain;base64,CmRlZiBsYXRlbnRfcmVjdXJzaW9uKHgsIHksIHosIG49Nik6CiAgICBmb3IgaSBpbiByYW5nZShuKTogIyBsYXRlbnQgcmVjdXJzaW9uCiAgICAgICAgeltpXSA9IG5ldCh4LCB5LCB6WzBdLCAuLi4gLCB6W24tMV0pCiAgICB5ID0gbmV0KHksIHpbMF0sIC4uLiAsIHpbbi0xXSkgIyByZWZpbmUgb3V0cHV0IGFuc3dlcgogICAgcmV0dXJuIHksIHoKCmRlZiBkZWVwX3JlY3Vyc2lvbih4LCB5LCB6LCBuPTYsIFQ9Myk6CiAgICAjIHJlY3Vyc2luZyBULTEgdGltZXMgdG8gaW1wcm92ZSB5IGFuZCB6IChubyBncmFkaWVudHMgbmVlZGVkKQogICAgd2l0aCB0b3JjaC5ub19ncmFkKCk6CiAgICAgICAgZm9yIGogaW4gcmFuZ2UoVC0xKToKICAgICAgICAgICAgeSwgeiA9IGxhdGVudF9yZWN1cnNpb24oeCwgeSwgeiwgbikKICAgICMgcmVjdXJzaW5nIG9uY2UgdG8gaW1wcm92ZSB5IGFuZCB6CiAgICB5LCB6ID0gbGF0ZW50X3JlY3Vyc2lvbih4LCB5LCB6LCBuKQogICAgcmV0dXJuICh5LmRldGFjaCgpLCB6LmRldGFjaCgpKSwgb3V0cHV0X2hlYWQoeSksIFFfaGVhZCh5KQoKIyBEZWVwIFN1cGVydmlzaW9uCmZvciB4X2lucHV0LCB5X3RydWUgaW4gdHJhaW5fZGF0YWxvYWRlcjoKICAgIHksIHogPSB5X2luaXQsIHpfaW5pdAogICAgZm9yIHN0ZXAgaW4gcmFuZ2UoTl9zdXBlcnZpc2lvbik6CiAgICAgICAgeCA9IGlucHV0X2VtYmVkZGluZyh4X2lucHV0KQogICAgICAgICh5LCB6KSwgeV9oYXQsIHFfaGF0ID0gZGVlcF9yZWN1cnNpb24oeCwgeSwgeikKICAgICAgICBsb3NzID0gc29mdG1heF9jcm9zc19lbnRyb3B5KHlfaGF0LCB5X3RydWUpCiAgICAgICAgbG9zcyArPSBiaW5hcnlfY3Jvc3NfZW50cm9weShxX2hhdCwgKHlfaGF0ID09IHlfdHJ1ZSkpCiAgICAgICAgbG9zcy5iYWNrd2FyZCgpCiAgICAgICAgb3B0LnN0ZXAoKQogICAgICAgIG9wdC56ZXJvX2dyYWQoKQogICAgICAgIGlmIHFbMF0gPiAwOiAjIGVhcmx5LXN0b3BwaW5nCiAgICAgICAgICAgIGJyZWFr">⬇</a></div>
<div class="ltx_listingline" id="lstnumberx101">
</div>
<div class="ltx_listingline" id="lstnumberx102">
<span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">def</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">latent_recursion</span>(<span class="ltx_text ltx_lst_identifier">x</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">n</span>=6):
</div>
<div class="ltx_listingline" id="lstnumberx103">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">for</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">i</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">in</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword ltx_lst_keywords2" style="--ltx-fg-color:#0000FF;">range</span>(<span class="ltx_text ltx_lst_identifier">n</span>):<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_comment" style="--ltx-fg-color:#808080;">#<span class="ltx_text ltx_lst_space"> </span>latent<span class="ltx_text ltx_lst_space"> </span>recursion</span>
</div>
<div class="ltx_listingline" id="lstnumberx104">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>[<span class="ltx_text ltx_lst_identifier">i</span>]<span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">net</span>(<span class="ltx_text ltx_lst_identifier">x</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>[0],<span class="ltx_text ltx_lst_space"> </span>…<span class="ltx_text ltx_lst_space"> </span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>[<span class="ltx_text ltx_lst_identifier">n</span>-1])
</div>
<div class="ltx_listingline" id="lstnumberx105">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">net</span>(<span class="ltx_text ltx_lst_identifier">y</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>[0],<span class="ltx_text ltx_lst_space"> </span>…<span class="ltx_text ltx_lst_space"> </span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>[<span class="ltx_text ltx_lst_identifier">n</span>-1])<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_comment" style="--ltx-fg-color:#808080;">#<span class="ltx_text ltx_lst_space"> </span>refine<span class="ltx_text ltx_lst_space"> </span>output<span class="ltx_text ltx_lst_space"> </span>answer</span>
</div>
<div class="ltx_listingline" id="lstnumberx106">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">return</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>
</div>
<div class="ltx_listingline" id="lstnumberx107">
</div>
<div class="ltx_listingline" id="lstnumberx108">
<span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">def</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">deep_recursion</span>(<span class="ltx_text ltx_lst_identifier">x</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">n</span>=6,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">T</span>=3):
</div>
<div class="ltx_listingline" id="lstnumberx109">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_comment" style="--ltx-fg-color:#808080;">#<span class="ltx_text ltx_lst_space"> </span>recursing<span class="ltx_text ltx_lst_space"> </span>T-1<span class="ltx_text ltx_lst_space"> </span>times<span class="ltx_text ltx_lst_space"> </span>to<span class="ltx_text ltx_lst_space"> </span>improve<span class="ltx_text ltx_lst_space"> </span>y<span class="ltx_text ltx_lst_space"> </span>and<span class="ltx_text ltx_lst_space"> </span>z<span class="ltx_text ltx_lst_space"> </span>(no<span class="ltx_text ltx_lst_space"> </span>gradients<span class="ltx_text ltx_lst_space"> </span>needed)</span>
</div>
<div class="ltx_listingline" id="lstnumberx110">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">with</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">torch</span>.<span class="ltx_text ltx_lst_identifier">no_grad</span>():
</div>
<div class="ltx_listingline" id="lstnumberx111">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">for</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">j</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">in</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword ltx_lst_keywords2" style="--ltx-fg-color:#0000FF;">range</span>(<span class="ltx_text ltx_lst_identifier">T</span>-1):
</div>
<div class="ltx_listingline" id="lstnumberx112">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">latent_recursion</span>(<span class="ltx_text ltx_lst_identifier">x</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">n</span>)
</div>
<div class="ltx_listingline" id="lstnumberx113">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_comment" style="--ltx-fg-color:#808080;">#<span class="ltx_text ltx_lst_space"> </span>recursing<span class="ltx_text ltx_lst_space"> </span>once<span class="ltx_text ltx_lst_space"> </span>to<span class="ltx_text ltx_lst_space"> </span>improve<span class="ltx_text ltx_lst_space"> </span>y<span class="ltx_text ltx_lst_space"> </span>and<span class="ltx_text ltx_lst_space"> </span>z</span>
</div>
<div class="ltx_listingline" id="lstnumberx114">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">latent_recursion</span>(<span class="ltx_text ltx_lst_identifier">x</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">n</span>)
</div>
<div class="ltx_listingline" id="lstnumberx115">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">return</span><span class="ltx_text ltx_lst_space"> </span>(<span class="ltx_text ltx_lst_identifier">y</span>.<span class="ltx_text ltx_lst_identifier">detach</span>(),<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>.<span class="ltx_text ltx_lst_identifier">detach</span>()),<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">output_head</span>(<span class="ltx_text ltx_lst_identifier">y</span>),<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">Q_head</span>(<span class="ltx_text ltx_lst_identifier">y</span>)
</div>
<div class="ltx_listingline" id="lstnumberx116">
</div>
<div class="ltx_listingline" id="lstnumberx117">
<span class="ltx_text ltx_lst_comment" style="--ltx-fg-color:#808080;">#<span class="ltx_text ltx_lst_space"> </span>Deep<span class="ltx_text ltx_lst_space"> </span>Supervision</span>
</div>
<div class="ltx_listingline" id="lstnumberx118">
<span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">for</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">x_input</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y_true</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">in</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">train_dataloader</span>:
</div>
<div class="ltx_listingline" id="lstnumberx119">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y_init</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z_init</span>
</div>
<div class="ltx_listingline" id="lstnumberx120">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">for</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">step</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">in</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword ltx_lst_keywords2" style="--ltx-fg-color:#0000FF;">range</span>(<span class="ltx_text ltx_lst_identifier">N_supervision</span>):
</div>
<div class="ltx_listingline" id="lstnumberx121">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">x</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">input_embedding</span>(<span class="ltx_text ltx_lst_identifier">x_input</span>)
</div>
<div class="ltx_listingline" id="lstnumberx122">
<span class="ltx_text ltx_lst_space"> </span>(<span class="ltx_text ltx_lst_identifier">y</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>),<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y_hat</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">q_hat</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">deep_recursion</span>(<span class="ltx_text ltx_lst_identifier">x</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">z</span>)
</div>
<div class="ltx_listingline" id="lstnumberx123">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">loss</span><span class="ltx_text ltx_lst_space"> </span>=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">softmax_cross_entropy</span>(<span class="ltx_text ltx_lst_identifier">y_hat</span>,<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y_true</span>)
</div>
<div class="ltx_listingline" id="lstnumberx124">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">loss</span><span class="ltx_text ltx_lst_space"> </span>+=<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">binary_cross_entropy</span>(<span class="ltx_text ltx_lst_identifier">q_hat</span>,<span class="ltx_text ltx_lst_space"> </span>(<span class="ltx_text ltx_lst_identifier">y_hat</span><span class="ltx_text ltx_lst_space"> </span>==<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">y_true</span>))
</div>
<div class="ltx_listingline" id="lstnumberx125">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">loss</span>.<span class="ltx_text ltx_lst_identifier">backward</span>()
</div>
<div class="ltx_listingline" id="lstnumberx126">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">opt</span>.<span class="ltx_text ltx_lst_identifier">step</span>()
</div>
<div class="ltx_listingline" id="lstnumberx127">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">opt</span>.<span class="ltx_text ltx_lst_identifier">zero_grad</span>()
</div>
<div class="ltx_listingline" id="lstnumberx128">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">if</span><span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_identifier">q</span>[0]<span class="ltx_text ltx_lst_space"> </span>&gt;<span class="ltx_text ltx_lst_space"> </span>0:<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_comment" style="--ltx-fg-color:#808080;">#<span class="ltx_text ltx_lst_space"> </span>early-stopping</span>
</div>
<div class="ltx_listingline" id="lstnumberx129">
<span class="ltx_text ltx_lst_space"> </span><span class="ltx_text ltx_lst_keyword" style="--ltx-fg-color:#0000FF;">break</span>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Pseudocode of TRM using multi-scale <math alttext="z" class="ltx_Math" display="inline" id="Ax3.F5.m2" intent=":literal"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math> with deep supervision training in PyTorch.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_appendix" id="Ax4">
<h2 class="ltx_title ltx_title_appendix">Example on Sudoku-Extreme</h2>
<figure class="ltx_figure" id="Ax4.F6"><span class="ltx_inline-block"><svg class="ltx_picture ltx_centering" height="655.68" id="Ax4.F6.pic1" overflow="visible" version="1.1" viewbox="0 0 220.27 655.68" width="220.27"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="translate(0,655.68) matrix(1 0 0 -1 0 0) translate(42.81,0) translate(0,520.2)"><path d="M 0 0 M 0 0 L 134.65 0 M 0 14.96 L 134.65 14.96 M 0 29.92 L 134.65 29.92 M 0 44.88 L 134.65 44.88 M 0 59.84 L 134.65 59.84 M 0 74.8 L 134.65 74.8 M 0 89.76 L 134.65 89.76 M 0 104.73 L 134.65 104.73 M 0 119.69 L 134.65 119.69 M 0 134.64 L 134.65 134.64 M 0 0 L 0 134.65 M 14.96 0 L 14.96 134.65 M 29.92 0 L 29.92 134.65 M 44.88 0 L 44.88 134.65 M 59.84 0 L 59.84 134.65 M 74.8 0 L 74.8 134.65 M 89.76 0 L 89.76 134.65 M 104.73 0 L 104.73 134.65 M 119.69 0 L 119.69 134.65 M 134.64 0 L 134.64 134.65 M 134.65 134.65" style="fill:none"></path><g stroke-width="1.2pt"><path d="M 0 0 M 0 0 L 134.65 0 M 0 44.88 L 134.65 44.88 M 0 89.76 L 134.65 89.76 M 0 134.63 L 134.65 134.63 M 0 0 L 0 134.65 M 44.88 0 L 44.88 134.65 M 89.76 0 L 89.76 134.65 M 134.63 0 L 134.63 134.65 M 134.65 134.65" style="fill:none"></path></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.04 0.01)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">8</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 0.48 0.01)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 1.01 0.01)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">1</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.67 -0.51)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">9</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.09 -0.51)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.57 -0.51)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">8</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 0.48 -0.51)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">7</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.62 -1.04)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.57 -1.04)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">5</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.67 -1.57)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.14 -1.57)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">8</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.57 -2.09)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.3 -2.09)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">2 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -5.5 -2.62)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">7 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.67 -2.62)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 1.01 -2.62)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.57 -3.14)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">9</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.3 -3.14)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -5.5 -3.67)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">2 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -3.4 -3.67)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 0.48 -3.67)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">1</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -5.5 -4.2)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -3.4 -4.2)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">2 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 0.48 -4.2)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">5</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 1.01 -4.2)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">7</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 44.34 -18.34)"><foreignobject height="12.15" overflow="visible" style="--fo_width :3.32em;--fo_height:0.68em;--fo_depth :0.19em;" transform="matrix(1 0 0 -1 0 9.46)" width="45.96"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">Input <math alttext="x" class="ltx_Math" display="inline" id="Ax4.F6.pic1.m1" intent=":literal"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math></span></span></foreignobject></g><path d="M 0 -164.57 M 0 -164.57 L 134.65 -164.57 M 0 -149.61 L 134.65 -149.61 M 0 -134.65 L 134.65 -134.65 M 0 -119.69 L 134.65 -119.69 M 0 -104.73 L 134.65 -104.73 M 0 -89.76 L 134.65 -89.76 M 0 -74.8 L 134.65 -74.8 M 0 -59.84 L 134.65 -59.84 M 0 -44.88 L 134.65 -44.88 M 0 -29.93 L 134.65 -29.93 M 0 -164.57 L 0 -29.92 M 14.96 -164.57 L 14.96 -29.92 M 29.92 -164.57 L 29.92 -29.92 M 44.88 -164.57 L 44.88 -29.92 M 59.84 -164.57 L 59.84 -29.92 M 74.8 -164.57 L 74.8 -29.92 M 89.76 -164.57 L 89.76 -29.92 M 104.73 -164.57 L 104.73 -29.92 M 119.69 -164.57 L 119.69 -29.92 M 134.64 -164.57 L 134.64 -29.92 M 134.65 -29.92" style="fill:none"></path><g stroke-width="1.2pt"><path d="M 0 -164.57 M 0 -164.57 L 134.65 -164.57 M 0 -119.69 L 134.65 -119.69 M 0 -74.8 L 134.65 -74.8 M 0 -29.94 L 134.65 -29.94 M 0 -164.57 L 0 -29.92 M 44.88 -164.57 L 44.88 -29.92 M 89.76 -164.57 L 89.76 -29.92 M 134.63 -164.57 L 134.63 -29.92 M 134.65 -29.92" style="fill:none"></path></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -5.5 -164.56)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">5 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.67 -164.56)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">2</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.14 -164.56)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.62 -164.56)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">7</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -3.4 -164.56)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">9 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.57 -164.56)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.04 -164.56)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">8</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 0.48 -164.56)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 1.01 -164.56)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">1</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -5.5 -165.08)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.67 -165.08)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">9</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -4.45 -165.08)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">1 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.62 -165.08)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">2</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.09 -165.08)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.57 -165.08)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">8</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.04 -165.08)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 0.48 -165.08)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">7</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 1.01 -165.08)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">5</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -5.5 -165.61)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.67 -165.61)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">8</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.14 -165.61)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">7</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.62 -165.61)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -3.4 -165.61)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">1 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.57 -165.61)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">5</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.35 -165.61)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">2 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 0.48 -165.61)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">9</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 1.01 -165.61)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -5.5 -166.14)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">1 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.67 -166.14)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.14 -166.14)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">8</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.62 -166.14)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">5</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.09 -166.14)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.57 -166.14)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">2</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.04 -166.14)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">7</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 0.48 -166.14)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.3 -166.14)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">9 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -5.5 -166.66)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">9 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.67 -166.66)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -4.45 -166.66)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">5 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.62 -166.66)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -3.4 -166.66)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">7 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.57 -166.66)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.04 -166.66)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">1</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 0.48 -166.66)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">8</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.3 -166.66)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">2 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -3.2 -167.19)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">7</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.67 -167.19)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -4.45 -167.19)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">2 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.62 -167.19)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">9</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.09 -167.19)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">8</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.57 -167.19)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">1</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.04 -167.19)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">5</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 0.48 -167.19)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.3 -167.19)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -3.2 -167.71)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">8</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.67 -167.71)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">7</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.14 -167.71)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.62 -167.71)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">1</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -3.4 -167.71)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">5 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.57 -167.71)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">9</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.04 -167.71)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 0.48 -167.71)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">2</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.3 -167.71)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -3.2 -168.24)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">2</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.67 -168.24)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">5</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -4.45 -168.24)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">9 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.62 -168.24)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.09 -168.24)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.57 -168.24)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">7</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.04 -168.24)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 0.48 -168.24)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">1</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.3 -168.24)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">8 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -3.2 -168.76)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.67 -168.76)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">1</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -4.45 -168.76)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.62 -168.76)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">8</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -3.4 -168.76)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">5 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.57 -168.76)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.04 -168.76)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">9</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 0.48 -168.76)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">5</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.3 -168.76)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">7 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 39.08 -182.91)"><foreignobject height="12.15" overflow="visible" style="--fo_width :4.08em;--fo_height:0.68em;--fo_depth :0.19em;" transform="matrix(1 0 0 -1 0 9.46)" width="56.48"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">Output <math alttext="y" class="ltx_Math" display="inline" id="Ax4.F6.pic1.m2" intent=":literal"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math></span></span></foreignobject></g><path d="M 0 -329.14 M 0 -329.14 L 134.65 -329.14 M 0 -314.18 L 134.65 -314.18 M 0 -299.22 L 134.65 -299.22 M 0 -284.26 L 134.65 -284.26 M 0 -269.29 L 134.65 -269.29 M 0 -254.33 L 134.65 -254.33 M 0 -239.37 L 134.65 -239.37 M 0 -224.41 L 134.65 -224.41 M 0 -209.45 L 134.65 -209.45 M 0 -194.5 L 134.65 -194.5 M 0 -329.14 L 0 -194.49 M 14.96 -329.14 L 14.96 -194.49 M 29.92 -329.14 L 29.92 -194.49 M 44.88 -329.14 L 44.88 -194.49 M 59.84 -329.14 L 59.84 -194.49 M 74.8 -329.14 L 74.8 -194.49 M 89.76 -329.14 L 89.76 -194.49 M 104.73 -329.14 L 104.73 -194.49 M 119.69 -329.14 L 119.69 -194.49 M 134.64 -329.14 L 134.64 -194.49 M 134.65 -194.49" style="fill:none"></path><g stroke-width="1.2pt"><path d="M 0 -329.14 M 0 -329.14 L 134.65 -329.14 M 0 -284.26 L 134.65 -284.26 M 0 -239.37 L 134.65 -239.37 M 0 -194.51 L 134.65 -194.51 M 0 -329.14 L 0 -194.49 M 44.88 -329.14 L 44.88 -194.49 M 89.76 -329.14 L 89.76 -194.49 M 134.63 -329.14 L 134.63 -194.49 M 134.65 -194.49" style="fill:none"></path></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -5.5 -329.13)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">5 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.67 -329.13)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">2</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.14 -329.13)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.62 -329.13)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">7</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -3.4 -329.13)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">9 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.57 -329.13)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.04 -329.13)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">8</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 0.48 -329.13)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 1.01 -329.13)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">1</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -5.5 -329.65)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.67 -329.65)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">9</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -4.45 -329.65)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">1 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.62 -329.65)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">2</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.09 -329.65)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.57 -329.65)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">8</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.04 -329.65)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 0.48 -329.65)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">7</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 1.01 -329.65)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">5</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -5.5 -330.18)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.67 -330.18)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">8</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.14 -330.18)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">7</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.62 -330.18)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -3.4 -330.18)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">1 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.57 -330.18)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">5</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.35 -330.18)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">2 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 0.48 -330.18)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">9</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 1.01 -330.18)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -5.5 -330.7)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">1 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.67 -330.7)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.14 -330.7)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">8</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.62 -330.7)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">5</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.09 -330.7)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.57 -330.7)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">2</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.04 -330.7)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">7</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 0.48 -330.7)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.3 -330.7)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">9 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -5.5 -331.23)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">9 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.67 -331.23)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -4.45 -331.23)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">5 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.62 -331.23)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -3.4 -331.23)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">7 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.57 -331.23)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.04 -331.23)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">1</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 0.48 -331.23)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">8</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.3 -331.23)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">2 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -3.2 -331.76)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">7</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.67 -331.76)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -4.45 -331.76)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">2 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.62 -331.76)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">9</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.09 -331.76)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">8</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.57 -331.76)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">1</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.04 -331.76)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">5</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 0.48 -331.76)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.3 -331.76)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -3.2 -332.28)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">8</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.67 -332.28)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">7</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.14 -332.28)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.62 -332.28)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">1</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -3.4 -332.28)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">5 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.57 -332.28)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">9</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.04 -332.28)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 0.48 -332.28)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">2</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.3 -332.28)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -3.2 -332.81)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">2</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.67 -332.81)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">5</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -4.45 -332.81)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">9 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.62 -332.81)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.09 -332.81)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.57 -332.81)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">7</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.04 -332.81)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 0.48 -332.81)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">1</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.3 -332.81)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">8 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -3.2 -333.33)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.67 -333.33)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">1</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -4.45 -333.33)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.62 -333.33)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">8</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -3.4 -333.33)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">5 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.57 -333.33)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.04 -333.33)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">9</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 0.48 -333.33)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">5</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.3 -333.33)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">7 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -38.2 -347.56)"><foreignobject height="13.84" overflow="visible" style="--fo_width :15.28em;--fo_height:0.75em;--fo_depth :0.25em;" transform="matrix(1 0 0 -1 0 10.38)" width="211.43"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">Tokenized <math alttext="z_{H}" class="ltx_Math" display="inline" id="Ax4.F6.pic1.m3" intent=":literal"><semantics><msub><mi>z</mi><mi>H</mi></msub><annotation encoding="application/x-tex">z_{H}</annotation></semantics></math> (denoted <math alttext="y" class="ltx_Math" display="inline" id="Ax4.F6.pic1.m4" intent=":literal"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math> in TRM)</span></span></foreignobject></g><path d="M 0 -493.71 M 0 -493.71 L 134.65 -493.71 M 0 -478.75 L 134.65 -478.75 M 0 -463.79 L 134.65 -463.79 M 0 -448.82 L 134.65 -448.82 M 0 -433.86 L 134.65 -433.86 M 0 -418.9 L 134.65 -418.9 M 0 -403.94 L 134.65 -403.94 M 0 -388.98 L 134.65 -388.98 M 0 -374.02 L 134.65 -374.02 M 0 -359.06 L 134.65 -359.06 M 0 -493.71 L 0 -359.06 M 14.96 -493.71 L 14.96 -359.06 M 29.92 -493.71 L 29.92 -359.06 M 44.88 -493.71 L 44.88 -359.06 M 59.84 -493.71 L 59.84 -359.06 M 74.8 -493.71 L 74.8 -359.06 M 89.76 -493.71 L 89.76 -359.06 M 104.73 -493.71 L 104.73 -359.06 M 119.69 -493.71 L 119.69 -359.06 M 134.64 -493.71 L 134.64 -359.06 M 134.65 -359.06" style="fill:none"></path><g stroke-width="1.2pt"><path d="M 0 -493.71 M 0 -493.71 L 134.65 -493.71 M 0 -448.82 L 134.65 -448.82 M 0 -403.94 L 134.65 -403.94 M 0 -359.08 L 134.65 -359.08 M 0 -493.71 L 0 -359.06 M 44.88 -493.71 L 44.88 -359.06 M 89.76 -493.71 L 89.76 -359.06 M 134.63 -493.71 L 134.63 -359.06 M 134.65 -359.06" style="fill:none"></path></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -5.5 -493.7)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">5 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.14 -493.7)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">5</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.62 -493.7)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -3.4 -493.7)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">9 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.57 -493.7)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 0.48 -493.7)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 1.01 -493.7)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -5.5 -494.22)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -4.45 -494.22)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.62 -494.22)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">1</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.04 -494.22)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 0.48 -494.22)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 1.01 -494.22)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">5</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -5.5 -494.75)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.67 -494.75)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">8</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.14 -494.75)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -3.4 -494.75)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.35 -494.75)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 0.48 -494.75)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 1.01 -494.75)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -5.5 -495.27)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">9 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.14 -495.27)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.62 -495.27)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">5</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.09 -495.27)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.04 -495.27)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">5</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 0.48 -495.27)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.67 -495.8)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -4.45 -495.8)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">5 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.62 -495.8)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -3.4 -495.8)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.04 -495.8)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">5</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 0.48 -495.8)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.3 -495.8)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -3.2 -496.33)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -4.45 -496.33)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.09 -496.33)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.57 -496.33)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.04 -496.33)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">5</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 0.48 -496.33)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">8</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.3 -496.33)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">8 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -3.2 -496.85)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.67 -496.85)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.14 -496.85)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.62 -496.85)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -3.4 -496.85)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">5 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.04 -496.85)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 0.48 -496.85)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.3 -496.85)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -3.2 -497.38)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">7</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.67 -497.38)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">5</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.62 -497.38)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.57 -497.38)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.04 -497.38)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 0.48 -497.38)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.3 -497.38)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -3.2 -497.9)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -2.67 -497.9)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -4.45 -497.9)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.62 -497.9)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">8</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.57 -497.9)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">3</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -0.04 -497.9)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 0.48 -497.9)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="6.92"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">6</span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -1.3 -497.9)"><foreignobject height="8.92" overflow="visible" style="--fo_width :0.83em;--fo_height:0.64em;--fo_depth :0em;" transform="matrix(1 0 0 -1 0 8.92)" width="11.53"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">4 </span></span></foreignobject></g><g fill="#000000" stroke="#000000" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="matrix(1.0 0.0 0.0 1.0 -36.97 -512.13)"><foreignobject height="13.84" overflow="visible" style="--fo_width :15.1em;--fo_height:0.75em;--fo_depth :0.25em;" transform="matrix(1 0 0 -1 0 10.38)" width="208.98"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">Tokenized <math alttext="z_{L}" class="ltx_Math" display="inline" id="Ax4.F6.pic1.m5" intent=":literal"><semantics><msub><mi>z</mi><mi>L</mi></msub><annotation encoding="application/x-tex">z_{L}</annotation></semantics></math> (denoted <math alttext="z" class="ltx_Math" display="inline" id="Ax4.F6.pic1.m6" intent=":literal"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math> in TRM)</span></span></foreignobject></g></g></svg></span>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>This Sudoku-Extreme example shows an input, expected output, and the tokenized <math alttext="z_{H}" class="ltx_Math" display="inline" id="Ax4.F6.m7" intent=":literal"><semantics><msub><mi>z</mi><mi>H</mi></msub><annotation encoding="application/x-tex">z_{H}</annotation></semantics></math> and <math alttext="z_{L}" class="ltx_Math" display="inline" id="Ax4.F6.m8" intent=":literal"><semantics><msub><mi>z</mi><mi>L</mi></msub><annotation encoding="application/x-tex">z_{L}</annotation></semantics></math> (after reversing the embedding and using argmax) for a pretrained model. This highlights the fact that <math alttext="z_{H}" class="ltx_Math" display="inline" id="Ax4.F6.m9" intent=":literal"><semantics><msub><mi>z</mi><mi>H</mi></msub><annotation encoding="application/x-tex">z_{H}</annotation></semantics></math> corresponds to the predicted response, while <math alttext="z_{L}" class="ltx_Math" display="inline" id="Ax4.F6.m10" intent=":literal"><semantics><msub><mi>z</mi><mi>L</mi></msub><annotation encoding="application/x-tex">z_{L}</annotation></semantics></math> is a latent feature that cannot be decoded to a sensible output unless transformed into <math alttext="z_{H}" class="ltx_Math" display="inline" id="Ax4.F6.m11" intent=":literal"><semantics><msub><mi>z</mi><mi>H</mi></msub><annotation encoding="application/x-tex">z_{H}</annotation></semantics></math> by <math alttext="f_{H}" class="ltx_Math" display="inline" id="Ax4.F6.m12" intent=":literal"><semantics><msub><mi>f</mi><mi>H</mi></msub><annotation encoding="application/x-tex">f_{H}</annotation></semantics></math>.</figcaption>
</figure>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Mon Oct  6 14:56:44 2025 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
